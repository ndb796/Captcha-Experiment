{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Captcha Experiment (CNN Basic, Gray).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ndb796/Captcha-Experiment/blob/master/colab/Captcha%20Experiment%20(CNN%20Basic%2C%20Gray).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ADOhm1fFU3N",
        "colab_type": "code",
        "outputId": "42b065bd-c28a-4d6d-fd41-113a351a25b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "!pip install captcha"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: captcha in /usr/local/lib/python3.6/dist-packages (0.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from captcha) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->captcha) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb3X_CUZ3NFL",
        "colab_type": "code",
        "outputId": "6bd3cec6-c507-460e-95cb-f4c20012db91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "''' Captcha Setting '''\n",
        "\n",
        "import os\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# character_set = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "character_set = '0123456789'\n",
        "character_set_length = len(character_set)\n",
        "\n",
        "number_per_image = 4\n",
        "width = 40 + 20 * number_per_image\n",
        "height = 100\n",
        "\n",
        "train_dataset_path = 'dataset' + os.path.sep + 'train'\n",
        "test_dataset_path = 'dataset' + os.path.sep + 'test'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "class Dataset():\n",
        "    def __init__(self, folder, transform=None):\n",
        "        self.train_image_file_paths = [os.path.join(folder, image_file) for image_file in os.listdir(folder)]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train_image_file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_root = self.train_image_file_paths[idx]\n",
        "        image_name = image_root.split(os.path.sep)[-1]\n",
        "        image = Image.open(image_root)\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        label = encode(image_name.split('_')[0])\n",
        "        return image, label\n",
        "\n",
        "\n",
        "def get_train_data_loader():\n",
        "    dataset = Dataset(train_dataset_path, transform=transform)\n",
        "    return DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "\n",
        "def get_test_data_loader():\n",
        "    dataset = Dataset(test_dataset_path, transform=transform)\n",
        "    return DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "\n",
        "def char2pos(c):\n",
        "    if c == '_':\n",
        "        k = 62\n",
        "        return k\n",
        "    k = ord(c) - 48\n",
        "    if k > 9:\n",
        "        k = ord(c) - 65 + 10\n",
        "        if k > 35:\n",
        "            k = ord(c) - 97 + 26 + 10\n",
        "            if k > 61:\n",
        "                raise ValueError('error')\n",
        "    return k\n",
        "\n",
        "\n",
        "def encode(text):\n",
        "    vector = np.zeros(character_set_length * number_per_image, dtype=float)\n",
        "    for i, c in enumerate(text):\n",
        "        idx = i * character_set_length + char2pos(c)\n",
        "        vector[idx] = 1.0\n",
        "    return vector\n",
        "\n",
        "\n",
        "def decode(vec):\n",
        "    char_pos = vec.nonzero()[0]\n",
        "    text = []\n",
        "    for i, c in enumerate(char_pos):\n",
        "        char_idx = c % character_set_length\n",
        "        if char_idx < 10:\n",
        "            char_code = char_idx + ord('0')\n",
        "        elif char_idx < 36:\n",
        "            char_code = char_idx - 10 + ord('A')\n",
        "        elif char_idx < 62:\n",
        "            char_code = char_idx - 36 + ord('a')\n",
        "        elif char_idx == 62:\n",
        "            char_code = ord('_')\n",
        "        else:\n",
        "            raise ValueError('error')\n",
        "        text.append(chr(char_code))\n",
        "    return \"\".join(text)\n",
        "\n",
        "\n",
        "e = encode(\"8937\")\n",
        "print(e)\n",
        "print(decode(e))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "8937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBhdtl4N3FoG",
        "colab_type": "code",
        "outputId": "2090cd61-80f6-4f87-e777-6fe6a0555c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "''' Captcha Generator '''\n",
        "\n",
        "from captcha.image import ImageCaptcha\n",
        "import itertools\n",
        "import os\n",
        "import shutil\n",
        "import uuid\n",
        "\n",
        "\n",
        "def generate_captcha(directory, characters, n):\n",
        "    if os.path.exists(directory):\n",
        "        shutil.rmtree(directory)\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    image = ImageCaptcha(width=width, height=height)\n",
        "    for count in range(1, n + 1):\n",
        "        print('Generating: (' + str(count) + '/' + str(n) + ')')\n",
        "        for i in itertools.permutations(characters, number_per_image):\n",
        "            captcha = ''.join(i)\n",
        "            file_name = directory + '/' + captcha + '_' + str(uuid.uuid4()) + '.png'\n",
        "            image.write(captcha, file_name)\n",
        "\n",
        "\n",
        "# Execute\n",
        "generate_captcha(train_dataset_path, character_set, 6) # n = 3: 70%, n = 6: \n",
        "generate_captcha(test_dataset_path, character_set, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating: (1/6)\n",
            "Generating: (2/6)\n",
            "Generating: (3/6)\n",
            "Generating: (4/6)\n",
            "Generating: (5/6)\n",
            "Generating: (6/6)\n",
            "Generating: (1/1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59Fp0XHH3KML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' Captcha Model '''\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# CNN Model (2 Convolution Layer)\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Dropout(0.5),  # drop 50% of the neuron\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(0.5),  # drop 50% of the neuron\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(0.5),  # drop 50% of the neuron\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear((width // 8) * (height // 8) * 64, 1024),\n",
        "            nn.Dropout(0.5),  # drop 50% of the neuron\n",
        "            nn.ReLU())\n",
        "        self.rfc = nn.Sequential(\n",
        "            nn.Linear(1024, number_per_image * character_set_length),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.rfc(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlGu90Pr32Wc",
        "colab_type": "code",
        "outputId": "5a9ebaeb-f2cf-4e09-b0d6-a249b050fd2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "''' Captcha Train '''\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "# Hyper Parameters\n",
        "num_epochs = 30\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "def main():\n",
        "    # GPU Setting\n",
        "    use_cuda = True\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        print('Cuda Available')\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    cnn = CNN()\n",
        "    cnn.to(device)\n",
        "    cnn.train()\n",
        "    \n",
        "    print('Model Initialization')\n",
        "    criterion = nn.MultiLabelSoftMarginLoss()\n",
        "    optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Train the Model\n",
        "    train_data_loader = get_train_data_loader()\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, labels) in enumerate(train_data_loader):\n",
        "            images = Variable(images).to(device)\n",
        "            labels = Variable(labels.float()).to(device)\n",
        "            predict_labels = cnn(images)\n",
        "            loss = criterion(predict_labels, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if (i + 1) % 10 == 0:\n",
        "                print(\"epoch:\", epoch, \"step:\", i, \"loss:\", loss.item())\n",
        "            if (i + 1) % 100 == 0:\n",
        "                torch.save(cnn.state_dict(), \"./model.pkl\")\n",
        "                print(\"Model Saved\")\n",
        "        print(\"epoch:\", epoch, \"step:\", i, \"loss:\", loss.item())\n",
        "    torch.save(cnn.state_dict(), \"./model.pkl\")\n",
        "    print(\"Last Model Saved\")\n",
        "\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda Available\n",
            "Model Initialization\n",
            "epoch: 0 step: 9 loss: 0.3802366256713867\n",
            "epoch: 0 step: 19 loss: 0.3388024568557739\n",
            "epoch: 0 step: 29 loss: 0.3370249569416046\n",
            "epoch: 0 step: 39 loss: 0.33673155307769775\n",
            "epoch: 0 step: 49 loss: 0.33487895131111145\n",
            "epoch: 0 step: 59 loss: 0.3334570527076721\n",
            "epoch: 0 step: 69 loss: 0.32869869470596313\n",
            "epoch: 0 step: 79 loss: 0.32516375184059143\n",
            "epoch: 0 step: 89 loss: 0.31953591108322144\n",
            "epoch: 0 step: 99 loss: 0.3184945583343506\n",
            "Model Saved\n",
            "epoch: 0 step: 109 loss: 0.31147319078445435\n",
            "epoch: 0 step: 119 loss: 0.3075438439846039\n",
            "epoch: 0 step: 129 loss: 0.2915128767490387\n",
            "epoch: 0 step: 139 loss: 0.28029128909111023\n",
            "epoch: 0 step: 149 loss: 0.2822398543357849\n",
            "epoch: 0 step: 159 loss: 0.2706435024738312\n",
            "epoch: 0 step: 169 loss: 0.2694072723388672\n",
            "epoch: 0 step: 179 loss: 0.2491394579410553\n",
            "epoch: 0 step: 189 loss: 0.25083959102630615\n",
            "epoch: 0 step: 199 loss: 0.24862685799598694\n",
            "Model Saved\n",
            "epoch: 0 step: 209 loss: 0.2509981393814087\n",
            "epoch: 0 step: 219 loss: 0.23360544443130493\n",
            "epoch: 0 step: 229 loss: 0.23388274013996124\n",
            "epoch: 0 step: 239 loss: 0.2246701717376709\n",
            "epoch: 0 step: 249 loss: 0.21458446979522705\n",
            "epoch: 0 step: 259 loss: 0.23510247468948364\n",
            "epoch: 0 step: 269 loss: 0.2146586775779724\n",
            "epoch: 0 step: 279 loss: 0.2226366251707077\n",
            "epoch: 0 step: 289 loss: 0.19232560694217682\n",
            "epoch: 0 step: 299 loss: 0.1983456164598465\n",
            "Model Saved\n",
            "epoch: 0 step: 309 loss: 0.21931561827659607\n",
            "epoch: 0 step: 319 loss: 0.2064845710992813\n",
            "epoch: 0 step: 329 loss: 0.204515278339386\n",
            "epoch: 0 step: 339 loss: 0.1737593114376068\n",
            "epoch: 0 step: 349 loss: 0.1761723756790161\n",
            "epoch: 0 step: 359 loss: 0.20226392149925232\n",
            "epoch: 0 step: 369 loss: 0.18919041752815247\n",
            "epoch: 0 step: 379 loss: 0.1768084466457367\n",
            "epoch: 0 step: 389 loss: 0.1770058572292328\n",
            "epoch: 0 step: 399 loss: 0.18439209461212158\n",
            "Model Saved\n",
            "epoch: 0 step: 409 loss: 0.16443923115730286\n",
            "epoch: 0 step: 419 loss: 0.18647047877311707\n",
            "epoch: 0 step: 429 loss: 0.1749533712863922\n",
            "epoch: 0 step: 439 loss: 0.1790808141231537\n",
            "epoch: 0 step: 449 loss: 0.17614957690238953\n",
            "epoch: 0 step: 459 loss: 0.1658197045326233\n",
            "epoch: 0 step: 469 loss: 0.16849255561828613\n",
            "epoch: 0 step: 472 loss: 0.16557100415229797\n",
            "epoch: 1 step: 9 loss: 0.16750924289226532\n",
            "epoch: 1 step: 19 loss: 0.15602165460586548\n",
            "epoch: 1 step: 29 loss: 0.1616591513156891\n",
            "epoch: 1 step: 39 loss: 0.16883495450019836\n",
            "epoch: 1 step: 49 loss: 0.1642477810382843\n",
            "epoch: 1 step: 59 loss: 0.15350806713104248\n",
            "epoch: 1 step: 69 loss: 0.17032018303871155\n",
            "epoch: 1 step: 79 loss: 0.14645081758499146\n",
            "epoch: 1 step: 89 loss: 0.163173645734787\n",
            "epoch: 1 step: 99 loss: 0.147223562002182\n",
            "Model Saved\n",
            "epoch: 1 step: 109 loss: 0.14276297390460968\n",
            "epoch: 1 step: 119 loss: 0.15633977949619293\n",
            "epoch: 1 step: 129 loss: 0.15469488501548767\n",
            "epoch: 1 step: 139 loss: 0.14006350934505463\n",
            "epoch: 1 step: 149 loss: 0.16002127528190613\n",
            "epoch: 1 step: 159 loss: 0.15243229269981384\n",
            "epoch: 1 step: 169 loss: 0.14607441425323486\n",
            "epoch: 1 step: 179 loss: 0.15586212277412415\n",
            "epoch: 1 step: 189 loss: 0.1612682044506073\n",
            "epoch: 1 step: 199 loss: 0.14973139762878418\n",
            "Model Saved\n",
            "epoch: 1 step: 209 loss: 0.15096443891525269\n",
            "epoch: 1 step: 219 loss: 0.15090832114219666\n",
            "epoch: 1 step: 229 loss: 0.13989436626434326\n",
            "epoch: 1 step: 239 loss: 0.13210567831993103\n",
            "epoch: 1 step: 249 loss: 0.13016176223754883\n",
            "epoch: 1 step: 259 loss: 0.14051489531993866\n",
            "epoch: 1 step: 269 loss: 0.13789542019367218\n",
            "epoch: 1 step: 279 loss: 0.1302209198474884\n",
            "epoch: 1 step: 289 loss: 0.1394066959619522\n",
            "epoch: 1 step: 299 loss: 0.13273152709007263\n",
            "Model Saved\n",
            "epoch: 1 step: 309 loss: 0.14658764004707336\n",
            "epoch: 1 step: 319 loss: 0.12459171563386917\n",
            "epoch: 1 step: 329 loss: 0.12843799591064453\n",
            "epoch: 1 step: 339 loss: 0.13009977340698242\n",
            "epoch: 1 step: 349 loss: 0.12382235378026962\n",
            "epoch: 1 step: 359 loss: 0.13072361052036285\n",
            "epoch: 1 step: 369 loss: 0.13191278278827667\n",
            "epoch: 1 step: 379 loss: 0.12046177685260773\n",
            "epoch: 1 step: 389 loss: 0.11237560957670212\n",
            "epoch: 1 step: 399 loss: 0.140761137008667\n",
            "Model Saved\n",
            "epoch: 1 step: 409 loss: 0.1204054206609726\n",
            "epoch: 1 step: 419 loss: 0.11910344660282135\n",
            "epoch: 1 step: 429 loss: 0.13733351230621338\n",
            "epoch: 1 step: 439 loss: 0.13921868801116943\n",
            "epoch: 1 step: 449 loss: 0.12864968180656433\n",
            "epoch: 1 step: 459 loss: 0.13712158799171448\n",
            "epoch: 1 step: 469 loss: 0.12190032005310059\n",
            "epoch: 1 step: 472 loss: 0.1360958069562912\n",
            "epoch: 2 step: 9 loss: 0.14235007762908936\n",
            "epoch: 2 step: 19 loss: 0.1269289255142212\n",
            "epoch: 2 step: 29 loss: 0.11745142936706543\n",
            "epoch: 2 step: 39 loss: 0.12527760863304138\n",
            "epoch: 2 step: 49 loss: 0.11802616715431213\n",
            "epoch: 2 step: 59 loss: 0.12104465067386627\n",
            "epoch: 2 step: 69 loss: 0.14115431904792786\n",
            "epoch: 2 step: 79 loss: 0.13571766018867493\n",
            "epoch: 2 step: 89 loss: 0.09575767815113068\n",
            "epoch: 2 step: 99 loss: 0.12116461247205734\n",
            "Model Saved\n",
            "epoch: 2 step: 109 loss: 0.1273997724056244\n",
            "epoch: 2 step: 119 loss: 0.12292954325675964\n",
            "epoch: 2 step: 129 loss: 0.11146363615989685\n",
            "epoch: 2 step: 139 loss: 0.12941834330558777\n",
            "epoch: 2 step: 149 loss: 0.1184554249048233\n",
            "epoch: 2 step: 159 loss: 0.12444613873958588\n",
            "epoch: 2 step: 169 loss: 0.11409353464841843\n",
            "epoch: 2 step: 179 loss: 0.12129112333059311\n",
            "epoch: 2 step: 189 loss: 0.10844787210226059\n",
            "epoch: 2 step: 199 loss: 0.11178042739629745\n",
            "Model Saved\n",
            "epoch: 2 step: 209 loss: 0.10518495738506317\n",
            "epoch: 2 step: 219 loss: 0.12655985355377197\n",
            "epoch: 2 step: 229 loss: 0.13005560636520386\n",
            "epoch: 2 step: 239 loss: 0.12315903604030609\n",
            "epoch: 2 step: 249 loss: 0.11357563734054565\n",
            "epoch: 2 step: 259 loss: 0.11721941828727722\n",
            "epoch: 2 step: 269 loss: 0.11654819548130035\n",
            "epoch: 2 step: 279 loss: 0.11595533788204193\n",
            "epoch: 2 step: 289 loss: 0.09779977798461914\n",
            "epoch: 2 step: 299 loss: 0.09825627505779266\n",
            "Model Saved\n",
            "epoch: 2 step: 309 loss: 0.10908602178096771\n",
            "epoch: 2 step: 319 loss: 0.11166846007108688\n",
            "epoch: 2 step: 329 loss: 0.11115659773349762\n",
            "epoch: 2 step: 339 loss: 0.10432419180870056\n",
            "epoch: 2 step: 349 loss: 0.09703829139471054\n",
            "epoch: 2 step: 359 loss: 0.09681927412748337\n",
            "epoch: 2 step: 369 loss: 0.10975299775600433\n",
            "epoch: 2 step: 379 loss: 0.09891998767852783\n",
            "epoch: 2 step: 389 loss: 0.09458942711353302\n",
            "epoch: 2 step: 399 loss: 0.11465546488761902\n",
            "Model Saved\n",
            "epoch: 2 step: 409 loss: 0.08975416421890259\n",
            "epoch: 2 step: 419 loss: 0.11244109272956848\n",
            "epoch: 2 step: 429 loss: 0.10161381214857101\n",
            "epoch: 2 step: 439 loss: 0.11606960743665695\n",
            "epoch: 2 step: 449 loss: 0.09946461021900177\n",
            "epoch: 2 step: 459 loss: 0.09983234107494354\n",
            "epoch: 2 step: 469 loss: 0.09834518283605576\n",
            "epoch: 2 step: 472 loss: 0.10511878877878189\n",
            "epoch: 3 step: 9 loss: 0.08894091844558716\n",
            "epoch: 3 step: 19 loss: 0.09830508381128311\n",
            "epoch: 3 step: 29 loss: 0.09024961292743683\n",
            "epoch: 3 step: 39 loss: 0.0929483026266098\n",
            "epoch: 3 step: 49 loss: 0.10801121592521667\n",
            "epoch: 3 step: 59 loss: 0.09121280908584595\n",
            "epoch: 3 step: 69 loss: 0.10401618480682373\n",
            "epoch: 3 step: 79 loss: 0.09364703297615051\n",
            "epoch: 3 step: 89 loss: 0.0861290842294693\n",
            "epoch: 3 step: 99 loss: 0.08947043120861053\n",
            "Model Saved\n",
            "epoch: 3 step: 109 loss: 0.08689907193183899\n",
            "epoch: 3 step: 119 loss: 0.09208238869905472\n",
            "epoch: 3 step: 129 loss: 0.10633815824985504\n",
            "epoch: 3 step: 139 loss: 0.08582095801830292\n",
            "epoch: 3 step: 149 loss: 0.08412739634513855\n",
            "epoch: 3 step: 159 loss: 0.09080496430397034\n",
            "epoch: 3 step: 169 loss: 0.10036449879407883\n",
            "epoch: 3 step: 179 loss: 0.1018274798989296\n",
            "epoch: 3 step: 189 loss: 0.10253007709980011\n",
            "epoch: 3 step: 199 loss: 0.11583203077316284\n",
            "Model Saved\n",
            "epoch: 3 step: 209 loss: 0.09329399466514587\n",
            "epoch: 3 step: 219 loss: 0.08954306691884995\n",
            "epoch: 3 step: 229 loss: 0.08934357762336731\n",
            "epoch: 3 step: 239 loss: 0.09083244949579239\n",
            "epoch: 3 step: 249 loss: 0.10955154895782471\n",
            "epoch: 3 step: 259 loss: 0.09479440748691559\n",
            "epoch: 3 step: 269 loss: 0.08884355425834656\n",
            "epoch: 3 step: 279 loss: 0.08248065412044525\n",
            "epoch: 3 step: 289 loss: 0.08309947699308395\n",
            "epoch: 3 step: 299 loss: 0.08585253357887268\n",
            "Model Saved\n",
            "epoch: 3 step: 309 loss: 0.1021817997097969\n",
            "epoch: 3 step: 319 loss: 0.0879276767373085\n",
            "epoch: 3 step: 329 loss: 0.09886607527732849\n",
            "epoch: 3 step: 339 loss: 0.10777109861373901\n",
            "epoch: 3 step: 349 loss: 0.08203105628490448\n",
            "epoch: 3 step: 359 loss: 0.08870673924684525\n",
            "epoch: 3 step: 369 loss: 0.08378341794013977\n",
            "epoch: 3 step: 379 loss: 0.08683668822050095\n",
            "epoch: 3 step: 389 loss: 0.09347374737262726\n",
            "epoch: 3 step: 399 loss: 0.10553769767284393\n",
            "Model Saved\n",
            "epoch: 3 step: 409 loss: 0.08645620942115784\n",
            "epoch: 3 step: 419 loss: 0.07920043170452118\n",
            "epoch: 3 step: 429 loss: 0.09875711798667908\n",
            "epoch: 3 step: 439 loss: 0.0920335054397583\n",
            "epoch: 3 step: 449 loss: 0.08962852507829666\n",
            "epoch: 3 step: 459 loss: 0.07664763927459717\n",
            "epoch: 3 step: 469 loss: 0.08423006534576416\n",
            "epoch: 3 step: 472 loss: 0.07806750386953354\n",
            "epoch: 4 step: 9 loss: 0.08738486468791962\n",
            "epoch: 4 step: 19 loss: 0.07715387642383575\n",
            "epoch: 4 step: 29 loss: 0.07505422830581665\n",
            "epoch: 4 step: 39 loss: 0.08323918282985687\n",
            "epoch: 4 step: 49 loss: 0.08476972579956055\n",
            "epoch: 4 step: 59 loss: 0.09107044339179993\n",
            "epoch: 4 step: 69 loss: 0.07570620626211166\n",
            "epoch: 4 step: 79 loss: 0.0666552186012268\n",
            "epoch: 4 step: 89 loss: 0.07010158151388168\n",
            "epoch: 4 step: 99 loss: 0.10146060585975647\n",
            "Model Saved\n",
            "epoch: 4 step: 109 loss: 0.08043044805526733\n",
            "epoch: 4 step: 119 loss: 0.08867637813091278\n",
            "epoch: 4 step: 129 loss: 0.09155389666557312\n",
            "epoch: 4 step: 139 loss: 0.08630361407995224\n",
            "epoch: 4 step: 149 loss: 0.0787418931722641\n",
            "epoch: 4 step: 159 loss: 0.07233938574790955\n",
            "epoch: 4 step: 169 loss: 0.07745188474655151\n",
            "epoch: 4 step: 179 loss: 0.08916563540697098\n",
            "epoch: 4 step: 189 loss: 0.07857486605644226\n",
            "epoch: 4 step: 199 loss: 0.0951155424118042\n",
            "Model Saved\n",
            "epoch: 4 step: 209 loss: 0.08093737065792084\n",
            "epoch: 4 step: 219 loss: 0.07538165152072906\n",
            "epoch: 4 step: 229 loss: 0.09882359206676483\n",
            "epoch: 4 step: 239 loss: 0.09342557191848755\n",
            "epoch: 4 step: 249 loss: 0.07491511106491089\n",
            "epoch: 4 step: 259 loss: 0.07073965668678284\n",
            "epoch: 4 step: 269 loss: 0.06744784116744995\n",
            "epoch: 4 step: 279 loss: 0.07192263007164001\n",
            "epoch: 4 step: 289 loss: 0.07636146247386932\n",
            "epoch: 4 step: 299 loss: 0.07511750608682632\n",
            "Model Saved\n",
            "epoch: 4 step: 309 loss: 0.07825416326522827\n",
            "epoch: 4 step: 319 loss: 0.08402135223150253\n",
            "epoch: 4 step: 329 loss: 0.07486486434936523\n",
            "epoch: 4 step: 339 loss: 0.10110118240118027\n",
            "epoch: 4 step: 349 loss: 0.07716920971870422\n",
            "epoch: 4 step: 359 loss: 0.07507891952991486\n",
            "epoch: 4 step: 369 loss: 0.08493955433368683\n",
            "epoch: 4 step: 379 loss: 0.08487994968891144\n",
            "epoch: 4 step: 389 loss: 0.08564116060733795\n",
            "epoch: 4 step: 399 loss: 0.09133287519216537\n",
            "Model Saved\n",
            "epoch: 4 step: 409 loss: 0.07707783579826355\n",
            "epoch: 4 step: 419 loss: 0.07847098261117935\n",
            "epoch: 4 step: 429 loss: 0.08017978072166443\n",
            "epoch: 4 step: 439 loss: 0.07822340726852417\n",
            "epoch: 4 step: 449 loss: 0.09120456874370575\n",
            "epoch: 4 step: 459 loss: 0.07129688560962677\n",
            "epoch: 4 step: 469 loss: 0.08537061512470245\n",
            "epoch: 4 step: 472 loss: 0.07695604860782623\n",
            "epoch: 5 step: 9 loss: 0.07647255063056946\n",
            "epoch: 5 step: 19 loss: 0.0773136243224144\n",
            "epoch: 5 step: 29 loss: 0.06595930457115173\n",
            "epoch: 5 step: 39 loss: 0.07234172523021698\n",
            "epoch: 5 step: 49 loss: 0.055349014699459076\n",
            "epoch: 5 step: 59 loss: 0.0691002905368805\n",
            "epoch: 5 step: 69 loss: 0.08139193058013916\n",
            "epoch: 5 step: 79 loss: 0.09769706428050995\n",
            "epoch: 5 step: 89 loss: 0.09163233637809753\n",
            "epoch: 5 step: 99 loss: 0.066196970641613\n",
            "Model Saved\n",
            "epoch: 5 step: 109 loss: 0.07329452037811279\n",
            "epoch: 5 step: 119 loss: 0.0655919536948204\n",
            "epoch: 5 step: 129 loss: 0.06508153676986694\n",
            "epoch: 5 step: 139 loss: 0.08265753090381622\n",
            "epoch: 5 step: 149 loss: 0.07485443353652954\n",
            "epoch: 5 step: 159 loss: 0.06507915258407593\n",
            "epoch: 5 step: 169 loss: 0.07808719575405121\n",
            "epoch: 5 step: 179 loss: 0.068433478474617\n",
            "epoch: 5 step: 189 loss: 0.06569089740514755\n",
            "epoch: 5 step: 199 loss: 0.0778779536485672\n",
            "Model Saved\n",
            "epoch: 5 step: 209 loss: 0.07421968877315521\n",
            "epoch: 5 step: 219 loss: 0.08179553598165512\n",
            "epoch: 5 step: 229 loss: 0.06437941640615463\n",
            "epoch: 5 step: 239 loss: 0.06895557045936584\n",
            "epoch: 5 step: 249 loss: 0.05950673669576645\n",
            "epoch: 5 step: 259 loss: 0.07651669532060623\n",
            "epoch: 5 step: 269 loss: 0.07129282504320145\n",
            "epoch: 5 step: 279 loss: 0.07299274206161499\n",
            "epoch: 5 step: 289 loss: 0.06359781324863434\n",
            "epoch: 5 step: 299 loss: 0.06758647412061691\n",
            "Model Saved\n",
            "epoch: 5 step: 309 loss: 0.06213308870792389\n",
            "epoch: 5 step: 319 loss: 0.06573671847581863\n",
            "epoch: 5 step: 329 loss: 0.08604076504707336\n",
            "epoch: 5 step: 339 loss: 0.06122708320617676\n",
            "epoch: 5 step: 349 loss: 0.06504854559898376\n",
            "epoch: 5 step: 359 loss: 0.060719624161720276\n",
            "epoch: 5 step: 369 loss: 0.08083826303482056\n",
            "epoch: 5 step: 379 loss: 0.04914999008178711\n",
            "epoch: 5 step: 389 loss: 0.06468501687049866\n",
            "epoch: 5 step: 399 loss: 0.06393782049417496\n",
            "Model Saved\n",
            "epoch: 5 step: 409 loss: 0.07185681164264679\n",
            "epoch: 5 step: 419 loss: 0.06363135576248169\n",
            "epoch: 5 step: 429 loss: 0.05620020627975464\n",
            "epoch: 5 step: 439 loss: 0.0675203800201416\n",
            "epoch: 5 step: 449 loss: 0.06146763637661934\n",
            "epoch: 5 step: 459 loss: 0.06349261105060577\n",
            "epoch: 5 step: 469 loss: 0.06134194880723953\n",
            "epoch: 5 step: 472 loss: 0.059156373143196106\n",
            "epoch: 6 step: 9 loss: 0.06329096853733063\n",
            "epoch: 6 step: 19 loss: 0.06025264412164688\n",
            "epoch: 6 step: 29 loss: 0.059642255306243896\n",
            "epoch: 6 step: 39 loss: 0.0645764172077179\n",
            "epoch: 6 step: 49 loss: 0.06619107723236084\n",
            "epoch: 6 step: 59 loss: 0.07096028327941895\n",
            "epoch: 6 step: 69 loss: 0.06687196344137192\n",
            "epoch: 6 step: 79 loss: 0.06236051023006439\n",
            "epoch: 6 step: 89 loss: 0.07255423814058304\n",
            "epoch: 6 step: 99 loss: 0.05757825821638107\n",
            "Model Saved\n",
            "epoch: 6 step: 109 loss: 0.06648814678192139\n",
            "epoch: 6 step: 119 loss: 0.0646418035030365\n",
            "epoch: 6 step: 129 loss: 0.08547774702310562\n",
            "epoch: 6 step: 139 loss: 0.06509221345186234\n",
            "epoch: 6 step: 149 loss: 0.07592575252056122\n",
            "epoch: 6 step: 159 loss: 0.0520593598484993\n",
            "epoch: 6 step: 169 loss: 0.07588928192853928\n",
            "epoch: 6 step: 179 loss: 0.0582880862057209\n",
            "epoch: 6 step: 189 loss: 0.05642580986022949\n",
            "epoch: 6 step: 199 loss: 0.059930749237537384\n",
            "Model Saved\n",
            "epoch: 6 step: 209 loss: 0.063719242811203\n",
            "epoch: 6 step: 219 loss: 0.061816710978746414\n",
            "epoch: 6 step: 229 loss: 0.051879361271858215\n",
            "epoch: 6 step: 239 loss: 0.057832758873701096\n",
            "epoch: 6 step: 249 loss: 0.06638365983963013\n",
            "epoch: 6 step: 259 loss: 0.05503874272108078\n",
            "epoch: 6 step: 269 loss: 0.06865553557872772\n",
            "epoch: 6 step: 279 loss: 0.05535192787647247\n",
            "epoch: 6 step: 289 loss: 0.06446277350187302\n",
            "epoch: 6 step: 299 loss: 0.0581323504447937\n",
            "Model Saved\n",
            "epoch: 6 step: 309 loss: 0.06286938488483429\n",
            "epoch: 6 step: 319 loss: 0.06070829555392265\n",
            "epoch: 6 step: 329 loss: 0.05224619805812836\n",
            "epoch: 6 step: 339 loss: 0.07422100007534027\n",
            "epoch: 6 step: 349 loss: 0.06280393898487091\n",
            "epoch: 6 step: 359 loss: 0.05350556597113609\n",
            "epoch: 6 step: 369 loss: 0.0558159314095974\n",
            "epoch: 6 step: 379 loss: 0.062016561627388\n",
            "epoch: 6 step: 389 loss: 0.06920621544122696\n",
            "epoch: 6 step: 399 loss: 0.051357269287109375\n",
            "Model Saved\n",
            "epoch: 6 step: 409 loss: 0.06536082923412323\n",
            "epoch: 6 step: 419 loss: 0.06042331084609032\n",
            "epoch: 6 step: 429 loss: 0.06304119527339935\n",
            "epoch: 6 step: 439 loss: 0.06760303676128387\n",
            "epoch: 6 step: 449 loss: 0.060833871364593506\n",
            "epoch: 6 step: 459 loss: 0.052254755049943924\n",
            "epoch: 6 step: 469 loss: 0.05303763598203659\n",
            "epoch: 6 step: 472 loss: 0.0628252625465393\n",
            "epoch: 7 step: 9 loss: 0.06890276074409485\n",
            "epoch: 7 step: 19 loss: 0.06422996520996094\n",
            "epoch: 7 step: 29 loss: 0.04837556183338165\n",
            "epoch: 7 step: 39 loss: 0.06612633168697357\n",
            "epoch: 7 step: 49 loss: 0.05819287896156311\n",
            "epoch: 7 step: 59 loss: 0.04618261381983757\n",
            "epoch: 7 step: 69 loss: 0.06287772208452225\n",
            "epoch: 7 step: 79 loss: 0.053980857133865356\n",
            "epoch: 7 step: 89 loss: 0.05961025506258011\n",
            "epoch: 7 step: 99 loss: 0.05598386004567146\n",
            "Model Saved\n",
            "epoch: 7 step: 109 loss: 0.0437806099653244\n",
            "epoch: 7 step: 119 loss: 0.06030036881566048\n",
            "epoch: 7 step: 129 loss: 0.05688256770372391\n",
            "epoch: 7 step: 139 loss: 0.06536580622196198\n",
            "epoch: 7 step: 149 loss: 0.06020238995552063\n",
            "epoch: 7 step: 159 loss: 0.066886767745018\n",
            "epoch: 7 step: 169 loss: 0.05464751273393631\n",
            "epoch: 7 step: 179 loss: 0.062156133353710175\n",
            "epoch: 7 step: 189 loss: 0.07138354331254959\n",
            "epoch: 7 step: 199 loss: 0.0734807699918747\n",
            "Model Saved\n",
            "epoch: 7 step: 209 loss: 0.06494549661874771\n",
            "epoch: 7 step: 219 loss: 0.05086922645568848\n",
            "epoch: 7 step: 229 loss: 0.0644371286034584\n",
            "epoch: 7 step: 239 loss: 0.06676672399044037\n",
            "epoch: 7 step: 249 loss: 0.05660057067871094\n",
            "epoch: 7 step: 259 loss: 0.06101752817630768\n",
            "epoch: 7 step: 269 loss: 0.05942708998918533\n",
            "epoch: 7 step: 279 loss: 0.06009305641055107\n",
            "epoch: 7 step: 289 loss: 0.04855934530496597\n",
            "epoch: 7 step: 299 loss: 0.050252191722393036\n",
            "Model Saved\n",
            "epoch: 7 step: 309 loss: 0.05150048807263374\n",
            "epoch: 7 step: 319 loss: 0.06097770854830742\n",
            "epoch: 7 step: 329 loss: 0.05617984011769295\n",
            "epoch: 7 step: 339 loss: 0.05533057451248169\n",
            "epoch: 7 step: 349 loss: 0.06241364777088165\n",
            "epoch: 7 step: 359 loss: 0.06326551735401154\n",
            "epoch: 7 step: 369 loss: 0.04867713898420334\n",
            "epoch: 7 step: 379 loss: 0.05504262447357178\n",
            "epoch: 7 step: 389 loss: 0.07380246371030807\n",
            "epoch: 7 step: 399 loss: 0.0531756654381752\n",
            "Model Saved\n",
            "epoch: 7 step: 409 loss: 0.06103884428739548\n",
            "epoch: 7 step: 419 loss: 0.062334172427654266\n",
            "epoch: 7 step: 429 loss: 0.053518421947956085\n",
            "epoch: 7 step: 439 loss: 0.05071695148944855\n",
            "epoch: 7 step: 449 loss: 0.0568978525698185\n",
            "epoch: 7 step: 459 loss: 0.06481201201677322\n",
            "epoch: 7 step: 469 loss: 0.05857393145561218\n",
            "epoch: 7 step: 472 loss: 0.06000693887472153\n",
            "epoch: 8 step: 9 loss: 0.05587134137749672\n",
            "epoch: 8 step: 19 loss: 0.051265887916088104\n",
            "epoch: 8 step: 29 loss: 0.047787949442863464\n",
            "epoch: 8 step: 39 loss: 0.049489714205265045\n",
            "epoch: 8 step: 49 loss: 0.0443790927529335\n",
            "epoch: 8 step: 59 loss: 0.04837431758642197\n",
            "epoch: 8 step: 69 loss: 0.050801895558834076\n",
            "epoch: 8 step: 79 loss: 0.04433263838291168\n",
            "epoch: 8 step: 89 loss: 0.051159195601940155\n",
            "epoch: 8 step: 99 loss: 0.052021563053131104\n",
            "Model Saved\n",
            "epoch: 8 step: 109 loss: 0.05128571018576622\n",
            "epoch: 8 step: 119 loss: 0.05719975754618645\n",
            "epoch: 8 step: 129 loss: 0.059317223727703094\n",
            "epoch: 8 step: 139 loss: 0.04655379801988602\n",
            "epoch: 8 step: 149 loss: 0.0485653355717659\n",
            "epoch: 8 step: 159 loss: 0.061491187661886215\n",
            "epoch: 8 step: 169 loss: 0.07811460644006729\n",
            "epoch: 8 step: 179 loss: 0.05751589313149452\n",
            "epoch: 8 step: 189 loss: 0.04881605505943298\n",
            "epoch: 8 step: 199 loss: 0.053640566766262054\n",
            "Model Saved\n",
            "epoch: 8 step: 209 loss: 0.0700480192899704\n",
            "epoch: 8 step: 219 loss: 0.0525464303791523\n",
            "epoch: 8 step: 229 loss: 0.06036006659269333\n",
            "epoch: 8 step: 239 loss: 0.0407160222530365\n",
            "epoch: 8 step: 249 loss: 0.057728253304958344\n",
            "epoch: 8 step: 259 loss: 0.051371313631534576\n",
            "epoch: 8 step: 269 loss: 0.05275836959481239\n",
            "epoch: 8 step: 279 loss: 0.05579578876495361\n",
            "epoch: 8 step: 289 loss: 0.043366529047489166\n",
            "epoch: 8 step: 299 loss: 0.04976049065589905\n",
            "Model Saved\n",
            "epoch: 8 step: 309 loss: 0.04292168468236923\n",
            "epoch: 8 step: 319 loss: 0.05141524225473404\n",
            "epoch: 8 step: 329 loss: 0.05696244165301323\n",
            "epoch: 8 step: 339 loss: 0.055117785930633545\n",
            "epoch: 8 step: 349 loss: 0.055017489939928055\n",
            "epoch: 8 step: 359 loss: 0.05110330134630203\n",
            "epoch: 8 step: 369 loss: 0.04387502744793892\n",
            "epoch: 8 step: 379 loss: 0.05739513412117958\n",
            "epoch: 8 step: 389 loss: 0.056142810732126236\n",
            "epoch: 8 step: 399 loss: 0.06401550769805908\n",
            "Model Saved\n",
            "epoch: 8 step: 409 loss: 0.05045980215072632\n",
            "epoch: 8 step: 419 loss: 0.06278775632381439\n",
            "epoch: 8 step: 429 loss: 0.05432644858956337\n",
            "epoch: 8 step: 439 loss: 0.05400723218917847\n",
            "epoch: 8 step: 449 loss: 0.04403199255466461\n",
            "epoch: 8 step: 459 loss: 0.06368684768676758\n",
            "epoch: 8 step: 469 loss: 0.06780169904232025\n",
            "epoch: 8 step: 472 loss: 0.0487620085477829\n",
            "epoch: 9 step: 9 loss: 0.04811219871044159\n",
            "epoch: 9 step: 19 loss: 0.057435013353824615\n",
            "epoch: 9 step: 29 loss: 0.04483697935938835\n",
            "epoch: 9 step: 39 loss: 0.051852189004421234\n",
            "epoch: 9 step: 49 loss: 0.04845317453145981\n",
            "epoch: 9 step: 59 loss: 0.04668455943465233\n",
            "epoch: 9 step: 69 loss: 0.05040913075208664\n",
            "epoch: 9 step: 79 loss: 0.053770728409290314\n",
            "epoch: 9 step: 89 loss: 0.05151679366827011\n",
            "epoch: 9 step: 99 loss: 0.048798948526382446\n",
            "Model Saved\n",
            "epoch: 9 step: 109 loss: 0.05286037176847458\n",
            "epoch: 9 step: 119 loss: 0.04631330072879791\n",
            "epoch: 9 step: 129 loss: 0.04942209646105766\n",
            "epoch: 9 step: 139 loss: 0.052062712609767914\n",
            "epoch: 9 step: 149 loss: 0.0495566725730896\n",
            "epoch: 9 step: 159 loss: 0.04865669459104538\n",
            "epoch: 9 step: 169 loss: 0.05190305411815643\n",
            "epoch: 9 step: 179 loss: 0.05082482844591141\n",
            "epoch: 9 step: 189 loss: 0.06258084625005722\n",
            "epoch: 9 step: 199 loss: 0.04828599840402603\n",
            "Model Saved\n",
            "epoch: 9 step: 209 loss: 0.042387254536151886\n",
            "epoch: 9 step: 219 loss: 0.06321559101343155\n",
            "epoch: 9 step: 229 loss: 0.05478282645344734\n",
            "epoch: 9 step: 239 loss: 0.051024165004491806\n",
            "epoch: 9 step: 249 loss: 0.04635089635848999\n",
            "epoch: 9 step: 259 loss: 0.07040180265903473\n",
            "epoch: 9 step: 269 loss: 0.06389037519693375\n",
            "epoch: 9 step: 279 loss: 0.029861293733119965\n",
            "epoch: 9 step: 289 loss: 0.03913360834121704\n",
            "epoch: 9 step: 299 loss: 0.047002218663692474\n",
            "Model Saved\n",
            "epoch: 9 step: 309 loss: 0.05134502798318863\n",
            "epoch: 9 step: 319 loss: 0.05656155198812485\n",
            "epoch: 9 step: 329 loss: 0.06034756079316139\n",
            "epoch: 9 step: 339 loss: 0.05941057205200195\n",
            "epoch: 9 step: 349 loss: 0.05282093584537506\n",
            "epoch: 9 step: 359 loss: 0.04522121697664261\n",
            "epoch: 9 step: 369 loss: 0.040369097143411636\n",
            "epoch: 9 step: 379 loss: 0.045339569449424744\n",
            "epoch: 9 step: 389 loss: 0.03536052256822586\n",
            "epoch: 9 step: 399 loss: 0.038932472467422485\n",
            "Model Saved\n",
            "epoch: 9 step: 409 loss: 0.05443616956472397\n",
            "epoch: 9 step: 419 loss: 0.0581379234790802\n",
            "epoch: 9 step: 429 loss: 0.05351538956165314\n",
            "epoch: 9 step: 439 loss: 0.04603145644068718\n",
            "epoch: 9 step: 449 loss: 0.04670556262135506\n",
            "epoch: 9 step: 459 loss: 0.047983165830373764\n",
            "epoch: 9 step: 469 loss: 0.04582700878381729\n",
            "epoch: 9 step: 472 loss: 0.052002500742673874\n",
            "epoch: 10 step: 9 loss: 0.04662422090768814\n",
            "epoch: 10 step: 19 loss: 0.0504724383354187\n",
            "epoch: 10 step: 29 loss: 0.046214811503887177\n",
            "epoch: 10 step: 39 loss: 0.06595313549041748\n",
            "epoch: 10 step: 49 loss: 0.05598101019859314\n",
            "epoch: 10 step: 59 loss: 0.047443270683288574\n",
            "epoch: 10 step: 69 loss: 0.04055117443203926\n",
            "epoch: 10 step: 79 loss: 0.05060753598809242\n",
            "epoch: 10 step: 89 loss: 0.044439300894737244\n",
            "epoch: 10 step: 99 loss: 0.05475253239274025\n",
            "Model Saved\n",
            "epoch: 10 step: 109 loss: 0.039398618042469025\n",
            "epoch: 10 step: 119 loss: 0.048702068626880646\n",
            "epoch: 10 step: 129 loss: 0.055687904357910156\n",
            "epoch: 10 step: 139 loss: 0.0414004921913147\n",
            "epoch: 10 step: 149 loss: 0.0441010408103466\n",
            "epoch: 10 step: 159 loss: 0.037336066365242004\n",
            "epoch: 10 step: 169 loss: 0.041787054389715195\n",
            "epoch: 10 step: 179 loss: 0.05153597518801689\n",
            "epoch: 10 step: 189 loss: 0.05250042676925659\n",
            "epoch: 10 step: 199 loss: 0.0529283732175827\n",
            "Model Saved\n",
            "epoch: 10 step: 209 loss: 0.051420070230960846\n",
            "epoch: 10 step: 219 loss: 0.04938312619924545\n",
            "epoch: 10 step: 229 loss: 0.055690258741378784\n",
            "epoch: 10 step: 239 loss: 0.04081153869628906\n",
            "epoch: 10 step: 249 loss: 0.04446230083703995\n",
            "epoch: 10 step: 259 loss: 0.040899910032749176\n",
            "epoch: 10 step: 269 loss: 0.05177157372236252\n",
            "epoch: 10 step: 279 loss: 0.052016809582710266\n",
            "epoch: 10 step: 289 loss: 0.034058988094329834\n",
            "epoch: 10 step: 299 loss: 0.0413878932595253\n",
            "Model Saved\n",
            "epoch: 10 step: 309 loss: 0.03459176421165466\n",
            "epoch: 10 step: 319 loss: 0.04873216152191162\n",
            "epoch: 10 step: 329 loss: 0.04159831255674362\n",
            "epoch: 10 step: 339 loss: 0.03483475372195244\n",
            "epoch: 10 step: 349 loss: 0.0513639897108078\n",
            "epoch: 10 step: 359 loss: 0.04945416748523712\n",
            "epoch: 10 step: 369 loss: 0.04987886920571327\n",
            "epoch: 10 step: 379 loss: 0.0576629601418972\n",
            "epoch: 10 step: 389 loss: 0.04452940821647644\n",
            "epoch: 10 step: 399 loss: 0.04510677233338356\n",
            "Model Saved\n",
            "epoch: 10 step: 409 loss: 0.0452219657599926\n",
            "epoch: 10 step: 419 loss: 0.04289399832487106\n",
            "epoch: 10 step: 429 loss: 0.04079093784093857\n",
            "epoch: 10 step: 439 loss: 0.06347900629043579\n",
            "epoch: 10 step: 449 loss: 0.044853921979665756\n",
            "epoch: 10 step: 459 loss: 0.03841891884803772\n",
            "epoch: 10 step: 469 loss: 0.0481596440076828\n",
            "epoch: 10 step: 472 loss: 0.05833499878644943\n",
            "epoch: 11 step: 9 loss: 0.05247161537408829\n",
            "epoch: 11 step: 19 loss: 0.041275378316640854\n",
            "epoch: 11 step: 29 loss: 0.04226814955472946\n",
            "epoch: 11 step: 39 loss: 0.043084338307380676\n",
            "epoch: 11 step: 49 loss: 0.03931600600481033\n",
            "epoch: 11 step: 59 loss: 0.0508575439453125\n",
            "epoch: 11 step: 69 loss: 0.05289032682776451\n",
            "epoch: 11 step: 79 loss: 0.042854007333517075\n",
            "epoch: 11 step: 89 loss: 0.05017995461821556\n",
            "epoch: 11 step: 99 loss: 0.04667038470506668\n",
            "Model Saved\n",
            "epoch: 11 step: 109 loss: 0.03985421359539032\n",
            "epoch: 11 step: 119 loss: 0.054738543927669525\n",
            "epoch: 11 step: 129 loss: 0.046635501086711884\n",
            "epoch: 11 step: 139 loss: 0.038753949105739594\n",
            "epoch: 11 step: 149 loss: 0.03512357547879219\n",
            "epoch: 11 step: 159 loss: 0.037757568061351776\n",
            "epoch: 11 step: 169 loss: 0.04325169697403908\n",
            "epoch: 11 step: 179 loss: 0.04173705354332924\n",
            "epoch: 11 step: 189 loss: 0.038695622235536575\n",
            "epoch: 11 step: 199 loss: 0.046751122921705246\n",
            "Model Saved\n",
            "epoch: 11 step: 209 loss: 0.03281477838754654\n",
            "epoch: 11 step: 219 loss: 0.039808910340070724\n",
            "epoch: 11 step: 229 loss: 0.042572349309921265\n",
            "epoch: 11 step: 239 loss: 0.04547341540455818\n",
            "epoch: 11 step: 249 loss: 0.040830355137586594\n",
            "epoch: 11 step: 259 loss: 0.04568935185670853\n",
            "epoch: 11 step: 269 loss: 0.039888110011816025\n",
            "epoch: 11 step: 279 loss: 0.041720036417245865\n",
            "epoch: 11 step: 289 loss: 0.047456271946430206\n",
            "epoch: 11 step: 299 loss: 0.03627584129571915\n",
            "Model Saved\n",
            "epoch: 11 step: 309 loss: 0.04327675700187683\n",
            "epoch: 11 step: 319 loss: 0.037202104926109314\n",
            "epoch: 11 step: 329 loss: 0.043522898107767105\n",
            "epoch: 11 step: 339 loss: 0.0542498379945755\n",
            "epoch: 11 step: 349 loss: 0.034289147704839706\n",
            "epoch: 11 step: 359 loss: 0.03929920494556427\n",
            "epoch: 11 step: 369 loss: 0.0495082288980484\n",
            "epoch: 11 step: 379 loss: 0.03920898586511612\n",
            "epoch: 11 step: 389 loss: 0.041089970618486404\n",
            "epoch: 11 step: 399 loss: 0.04398713260889053\n",
            "Model Saved\n",
            "epoch: 11 step: 409 loss: 0.042635850608348846\n",
            "epoch: 11 step: 419 loss: 0.03745266795158386\n",
            "epoch: 11 step: 429 loss: 0.046098023653030396\n",
            "epoch: 11 step: 439 loss: 0.04804149642586708\n",
            "epoch: 11 step: 449 loss: 0.04548729956150055\n",
            "epoch: 11 step: 459 loss: 0.03220856934785843\n",
            "epoch: 11 step: 469 loss: 0.03466308116912842\n",
            "epoch: 11 step: 472 loss: 0.046761274337768555\n",
            "epoch: 12 step: 9 loss: 0.040404900908470154\n",
            "epoch: 12 step: 19 loss: 0.03909054398536682\n",
            "epoch: 12 step: 29 loss: 0.03959105908870697\n",
            "epoch: 12 step: 39 loss: 0.04536456614732742\n",
            "epoch: 12 step: 49 loss: 0.0413711741566658\n",
            "epoch: 12 step: 59 loss: 0.04673081636428833\n",
            "epoch: 12 step: 69 loss: 0.04188738018274307\n",
            "epoch: 12 step: 79 loss: 0.04874233528971672\n",
            "epoch: 12 step: 89 loss: 0.04347623512148857\n",
            "epoch: 12 step: 99 loss: 0.03725293651223183\n",
            "Model Saved\n",
            "epoch: 12 step: 109 loss: 0.0432450994849205\n",
            "epoch: 12 step: 119 loss: 0.03910106047987938\n",
            "epoch: 12 step: 129 loss: 0.059646256268024445\n",
            "epoch: 12 step: 139 loss: 0.03354163467884064\n",
            "epoch: 12 step: 149 loss: 0.046389371156692505\n",
            "epoch: 12 step: 159 loss: 0.03693041205406189\n",
            "epoch: 12 step: 169 loss: 0.03254503011703491\n",
            "epoch: 12 step: 179 loss: 0.037384845316410065\n",
            "epoch: 12 step: 189 loss: 0.03850630670785904\n",
            "epoch: 12 step: 199 loss: 0.04273325949907303\n",
            "Model Saved\n",
            "epoch: 12 step: 209 loss: 0.04056718945503235\n",
            "epoch: 12 step: 219 loss: 0.03067748062312603\n",
            "epoch: 12 step: 229 loss: 0.043119460344314575\n",
            "epoch: 12 step: 239 loss: 0.04651984944939613\n",
            "epoch: 12 step: 249 loss: 0.04600588232278824\n",
            "epoch: 12 step: 259 loss: 0.04396525397896767\n",
            "epoch: 12 step: 269 loss: 0.04919920116662979\n",
            "epoch: 12 step: 279 loss: 0.037803251296281815\n",
            "epoch: 12 step: 289 loss: 0.04119562357664108\n",
            "epoch: 12 step: 299 loss: 0.05237413942813873\n",
            "Model Saved\n",
            "epoch: 12 step: 309 loss: 0.04120123013854027\n",
            "epoch: 12 step: 319 loss: 0.03360636904835701\n",
            "epoch: 12 step: 329 loss: 0.039082568138837814\n",
            "epoch: 12 step: 339 loss: 0.05278560519218445\n",
            "epoch: 12 step: 349 loss: 0.04263877123594284\n",
            "epoch: 12 step: 359 loss: 0.03938613831996918\n",
            "epoch: 12 step: 369 loss: 0.031162485480308533\n",
            "epoch: 12 step: 379 loss: 0.04402155801653862\n",
            "epoch: 12 step: 389 loss: 0.043650392442941666\n",
            "epoch: 12 step: 399 loss: 0.04514487832784653\n",
            "Model Saved\n",
            "epoch: 12 step: 409 loss: 0.059147052466869354\n",
            "epoch: 12 step: 419 loss: 0.03731494024395943\n",
            "epoch: 12 step: 429 loss: 0.051322124898433685\n",
            "epoch: 12 step: 439 loss: 0.04565995931625366\n",
            "epoch: 12 step: 449 loss: 0.04876921325922012\n",
            "epoch: 12 step: 459 loss: 0.04431203752756119\n",
            "epoch: 12 step: 469 loss: 0.040410365909338\n",
            "epoch: 12 step: 472 loss: 0.05347288027405739\n",
            "epoch: 13 step: 9 loss: 0.035717181861400604\n",
            "epoch: 13 step: 19 loss: 0.03467825800180435\n",
            "epoch: 13 step: 29 loss: 0.0397694930434227\n",
            "epoch: 13 step: 39 loss: 0.03910670056939125\n",
            "epoch: 13 step: 49 loss: 0.044096607714891434\n",
            "epoch: 13 step: 59 loss: 0.03500695154070854\n",
            "epoch: 13 step: 69 loss: 0.044091805815696716\n",
            "epoch: 13 step: 79 loss: 0.03340121731162071\n",
            "epoch: 13 step: 89 loss: 0.03696512430906296\n",
            "epoch: 13 step: 99 loss: 0.03618641197681427\n",
            "Model Saved\n",
            "epoch: 13 step: 109 loss: 0.030350640416145325\n",
            "epoch: 13 step: 119 loss: 0.03521690517663956\n",
            "epoch: 13 step: 129 loss: 0.05168306827545166\n",
            "epoch: 13 step: 139 loss: 0.04416345804929733\n",
            "epoch: 13 step: 149 loss: 0.04303523898124695\n",
            "epoch: 13 step: 159 loss: 0.04642792418599129\n",
            "epoch: 13 step: 169 loss: 0.03945618122816086\n",
            "epoch: 13 step: 179 loss: 0.036916717886924744\n",
            "epoch: 13 step: 189 loss: 0.043110158294439316\n",
            "epoch: 13 step: 199 loss: 0.043811820447444916\n",
            "Model Saved\n",
            "epoch: 13 step: 209 loss: 0.03963395953178406\n",
            "epoch: 13 step: 219 loss: 0.04881914705038071\n",
            "epoch: 13 step: 229 loss: 0.03698213770985603\n",
            "epoch: 13 step: 239 loss: 0.040855586528778076\n",
            "epoch: 13 step: 249 loss: 0.044142499566078186\n",
            "epoch: 13 step: 259 loss: 0.03599044680595398\n",
            "epoch: 13 step: 269 loss: 0.03611176460981369\n",
            "epoch: 13 step: 279 loss: 0.0366218239068985\n",
            "epoch: 13 step: 289 loss: 0.04862479120492935\n",
            "epoch: 13 step: 299 loss: 0.03292354941368103\n",
            "Model Saved\n",
            "epoch: 13 step: 309 loss: 0.04989295452833176\n",
            "epoch: 13 step: 319 loss: 0.026559876278042793\n",
            "epoch: 13 step: 329 loss: 0.04037708789110184\n",
            "epoch: 13 step: 339 loss: 0.057193171232938766\n",
            "epoch: 13 step: 349 loss: 0.041132986545562744\n",
            "epoch: 13 step: 359 loss: 0.05057745426893234\n",
            "epoch: 13 step: 369 loss: 0.039306942373514175\n",
            "epoch: 13 step: 379 loss: 0.03713470697402954\n",
            "epoch: 13 step: 389 loss: 0.04659353196620941\n",
            "epoch: 13 step: 399 loss: 0.03641604632139206\n",
            "Model Saved\n",
            "epoch: 13 step: 409 loss: 0.03477985039353371\n",
            "epoch: 13 step: 419 loss: 0.04161763936281204\n",
            "epoch: 13 step: 429 loss: 0.041379041969776154\n",
            "epoch: 13 step: 439 loss: 0.03274858742952347\n",
            "epoch: 13 step: 449 loss: 0.03263827785849571\n",
            "epoch: 13 step: 459 loss: 0.03455658257007599\n",
            "epoch: 13 step: 469 loss: 0.028774898499250412\n",
            "epoch: 13 step: 472 loss: 0.028463002294301987\n",
            "epoch: 14 step: 9 loss: 0.027246590703725815\n",
            "epoch: 14 step: 19 loss: 0.04903799295425415\n",
            "epoch: 14 step: 29 loss: 0.04955335333943367\n",
            "epoch: 14 step: 39 loss: 0.044251762330532074\n",
            "epoch: 14 step: 49 loss: 0.03397032618522644\n",
            "epoch: 14 step: 59 loss: 0.03650880977511406\n",
            "epoch: 14 step: 69 loss: 0.04446609318256378\n",
            "epoch: 14 step: 79 loss: 0.03639150410890579\n",
            "epoch: 14 step: 89 loss: 0.04326104372739792\n",
            "epoch: 14 step: 99 loss: 0.04366287589073181\n",
            "Model Saved\n",
            "epoch: 14 step: 109 loss: 0.03748530521988869\n",
            "epoch: 14 step: 119 loss: 0.041080281138420105\n",
            "epoch: 14 step: 129 loss: 0.03494124859571457\n",
            "epoch: 14 step: 139 loss: 0.04814935475587845\n",
            "epoch: 14 step: 149 loss: 0.02735885977745056\n",
            "epoch: 14 step: 159 loss: 0.04581334441900253\n",
            "epoch: 14 step: 169 loss: 0.036212027072906494\n",
            "epoch: 14 step: 179 loss: 0.041529614478349686\n",
            "epoch: 14 step: 189 loss: 0.04370937868952751\n",
            "epoch: 14 step: 199 loss: 0.05012943223118782\n",
            "Model Saved\n",
            "epoch: 14 step: 209 loss: 0.03689374029636383\n",
            "epoch: 14 step: 219 loss: 0.032627202570438385\n",
            "epoch: 14 step: 229 loss: 0.03813886642456055\n",
            "epoch: 14 step: 239 loss: 0.03295966237783432\n",
            "epoch: 14 step: 249 loss: 0.04090164601802826\n",
            "epoch: 14 step: 259 loss: 0.03463532030582428\n",
            "epoch: 14 step: 269 loss: 0.03489675745368004\n",
            "epoch: 14 step: 279 loss: 0.03270888328552246\n",
            "epoch: 14 step: 289 loss: 0.04299253225326538\n",
            "epoch: 14 step: 299 loss: 0.030369210988283157\n",
            "Model Saved\n",
            "epoch: 14 step: 309 loss: 0.043211765587329865\n",
            "epoch: 14 step: 319 loss: 0.043299827724695206\n",
            "epoch: 14 step: 329 loss: 0.041848160326480865\n",
            "epoch: 14 step: 339 loss: 0.0374324694275856\n",
            "epoch: 14 step: 349 loss: 0.038384903222322464\n",
            "epoch: 14 step: 359 loss: 0.026785507798194885\n",
            "epoch: 14 step: 369 loss: 0.03207170218229294\n",
            "epoch: 14 step: 379 loss: 0.040853507816791534\n",
            "epoch: 14 step: 389 loss: 0.02387820929288864\n",
            "epoch: 14 step: 399 loss: 0.04243079945445061\n",
            "Model Saved\n",
            "epoch: 14 step: 409 loss: 0.04177574813365936\n",
            "epoch: 14 step: 419 loss: 0.03662861883640289\n",
            "epoch: 14 step: 429 loss: 0.03820596635341644\n",
            "epoch: 14 step: 439 loss: 0.027598299086093903\n",
            "epoch: 14 step: 449 loss: 0.03340042382478714\n",
            "epoch: 14 step: 459 loss: 0.03475440293550491\n",
            "epoch: 14 step: 469 loss: 0.04080977290868759\n",
            "epoch: 14 step: 472 loss: 0.027230428531765938\n",
            "epoch: 15 step: 9 loss: 0.03201960399746895\n",
            "epoch: 15 step: 19 loss: 0.03577617183327675\n",
            "epoch: 15 step: 29 loss: 0.034634385257959366\n",
            "epoch: 15 step: 39 loss: 0.04504413530230522\n",
            "epoch: 15 step: 49 loss: 0.026657290756702423\n",
            "epoch: 15 step: 59 loss: 0.036319851875305176\n",
            "epoch: 15 step: 69 loss: 0.03655819594860077\n",
            "epoch: 15 step: 79 loss: 0.031968362629413605\n",
            "epoch: 15 step: 89 loss: 0.03251480683684349\n",
            "epoch: 15 step: 99 loss: 0.036657363176345825\n",
            "Model Saved\n",
            "epoch: 15 step: 109 loss: 0.03833598643541336\n",
            "epoch: 15 step: 119 loss: 0.03663399815559387\n",
            "epoch: 15 step: 129 loss: 0.04503806680440903\n",
            "epoch: 15 step: 139 loss: 0.04404326528310776\n",
            "epoch: 15 step: 149 loss: 0.05031886324286461\n",
            "epoch: 15 step: 159 loss: 0.04242093488574028\n",
            "epoch: 15 step: 169 loss: 0.038400135934352875\n",
            "epoch: 15 step: 179 loss: 0.03896721825003624\n",
            "epoch: 15 step: 189 loss: 0.03263699635863304\n",
            "epoch: 15 step: 199 loss: 0.029824521392583847\n",
            "Model Saved\n",
            "epoch: 15 step: 209 loss: 0.03603822737932205\n",
            "epoch: 15 step: 219 loss: 0.039322081953287125\n",
            "epoch: 15 step: 229 loss: 0.027517464011907578\n",
            "epoch: 15 step: 239 loss: 0.04122558608651161\n",
            "epoch: 15 step: 249 loss: 0.029989633709192276\n",
            "epoch: 15 step: 259 loss: 0.039502277970314026\n",
            "epoch: 15 step: 269 loss: 0.03496062755584717\n",
            "epoch: 15 step: 279 loss: 0.04187175631523132\n",
            "epoch: 15 step: 289 loss: 0.027911454439163208\n",
            "epoch: 15 step: 299 loss: 0.03603076934814453\n",
            "Model Saved\n",
            "epoch: 15 step: 309 loss: 0.048326388001441956\n",
            "epoch: 15 step: 319 loss: 0.032568350434303284\n",
            "epoch: 15 step: 329 loss: 0.03527892008423805\n",
            "epoch: 15 step: 339 loss: 0.03662671893835068\n",
            "epoch: 15 step: 349 loss: 0.03653935715556145\n",
            "epoch: 15 step: 359 loss: 0.028680769726634026\n",
            "epoch: 15 step: 369 loss: 0.03313250094652176\n",
            "epoch: 15 step: 379 loss: 0.03545684367418289\n",
            "epoch: 15 step: 389 loss: 0.03149525821208954\n",
            "epoch: 15 step: 399 loss: 0.037349991500377655\n",
            "Model Saved\n",
            "epoch: 15 step: 409 loss: 0.03369247540831566\n",
            "epoch: 15 step: 419 loss: 0.044521354138851166\n",
            "epoch: 15 step: 429 loss: 0.03790245205163956\n",
            "epoch: 15 step: 439 loss: 0.037669479846954346\n",
            "epoch: 15 step: 449 loss: 0.035457149147987366\n",
            "epoch: 15 step: 459 loss: 0.03594287484884262\n",
            "epoch: 15 step: 469 loss: 0.033267781138420105\n",
            "epoch: 15 step: 472 loss: 0.02555731311440468\n",
            "epoch: 16 step: 9 loss: 0.04000524431467056\n",
            "epoch: 16 step: 19 loss: 0.04118942469358444\n",
            "epoch: 16 step: 29 loss: 0.025124527513980865\n",
            "epoch: 16 step: 39 loss: 0.032766249030828476\n",
            "epoch: 16 step: 49 loss: 0.029299763962626457\n",
            "epoch: 16 step: 59 loss: 0.02994367480278015\n",
            "epoch: 16 step: 69 loss: 0.036766644567251205\n",
            "epoch: 16 step: 79 loss: 0.030507640913128853\n",
            "epoch: 16 step: 89 loss: 0.03177620843052864\n",
            "epoch: 16 step: 99 loss: 0.04326942563056946\n",
            "Model Saved\n",
            "epoch: 16 step: 109 loss: 0.03281286731362343\n",
            "epoch: 16 step: 119 loss: 0.03302162140607834\n",
            "epoch: 16 step: 129 loss: 0.04635908082127571\n",
            "epoch: 16 step: 139 loss: 0.031132757663726807\n",
            "epoch: 16 step: 149 loss: 0.021127497777342796\n",
            "epoch: 16 step: 159 loss: 0.04261845722794533\n",
            "epoch: 16 step: 169 loss: 0.034163009375333786\n",
            "epoch: 16 step: 179 loss: 0.03432009369134903\n",
            "epoch: 16 step: 189 loss: 0.03385646641254425\n",
            "epoch: 16 step: 199 loss: 0.034688062965869904\n",
            "Model Saved\n",
            "epoch: 16 step: 209 loss: 0.03786443918943405\n",
            "epoch: 16 step: 219 loss: 0.039776965975761414\n",
            "epoch: 16 step: 229 loss: 0.03741965442895889\n",
            "epoch: 16 step: 239 loss: 0.03134096786379814\n",
            "epoch: 16 step: 249 loss: 0.033505260944366455\n",
            "epoch: 16 step: 259 loss: 0.024449581280350685\n",
            "epoch: 16 step: 269 loss: 0.033587440848350525\n",
            "epoch: 16 step: 279 loss: 0.022804418578743935\n",
            "epoch: 16 step: 289 loss: 0.04148346185684204\n",
            "epoch: 16 step: 299 loss: 0.03971491754055023\n",
            "Model Saved\n",
            "epoch: 16 step: 309 loss: 0.028378814458847046\n",
            "epoch: 16 step: 319 loss: 0.035918962210416794\n",
            "epoch: 16 step: 329 loss: 0.043038807809352875\n",
            "epoch: 16 step: 339 loss: 0.0335991270840168\n",
            "epoch: 16 step: 349 loss: 0.041369255632162094\n",
            "epoch: 16 step: 359 loss: 0.026938386261463165\n",
            "epoch: 16 step: 369 loss: 0.037457820028066635\n",
            "epoch: 16 step: 379 loss: 0.04292415454983711\n",
            "epoch: 16 step: 389 loss: 0.03758590668439865\n",
            "epoch: 16 step: 399 loss: 0.038315899670124054\n",
            "Model Saved\n",
            "epoch: 16 step: 409 loss: 0.0393480509519577\n",
            "epoch: 16 step: 419 loss: 0.04331764578819275\n",
            "epoch: 16 step: 429 loss: 0.030122075229883194\n",
            "epoch: 16 step: 439 loss: 0.03462645411491394\n",
            "epoch: 16 step: 449 loss: 0.0425591841340065\n",
            "epoch: 16 step: 459 loss: 0.0352078415453434\n",
            "epoch: 16 step: 469 loss: 0.03607472777366638\n",
            "epoch: 16 step: 472 loss: 0.05052965134382248\n",
            "epoch: 17 step: 9 loss: 0.02716933563351631\n",
            "epoch: 17 step: 19 loss: 0.032969750463962555\n",
            "epoch: 17 step: 29 loss: 0.033680908381938934\n",
            "epoch: 17 step: 39 loss: 0.030947361141443253\n",
            "epoch: 17 step: 49 loss: 0.03449859097599983\n",
            "epoch: 17 step: 59 loss: 0.03131683170795441\n",
            "epoch: 17 step: 69 loss: 0.02593829482793808\n",
            "epoch: 17 step: 79 loss: 0.029710737988352776\n",
            "epoch: 17 step: 89 loss: 0.032975949347019196\n",
            "epoch: 17 step: 99 loss: 0.03141406178474426\n",
            "Model Saved\n",
            "epoch: 17 step: 109 loss: 0.04001734033226967\n",
            "epoch: 17 step: 119 loss: 0.03555909916758537\n",
            "epoch: 17 step: 129 loss: 0.03665076196193695\n",
            "epoch: 17 step: 139 loss: 0.026599980890750885\n",
            "epoch: 17 step: 149 loss: 0.03582127392292023\n",
            "epoch: 17 step: 159 loss: 0.03634919971227646\n",
            "epoch: 17 step: 169 loss: 0.03230726718902588\n",
            "epoch: 17 step: 179 loss: 0.04168921709060669\n",
            "epoch: 17 step: 189 loss: 0.0408344492316246\n",
            "epoch: 17 step: 199 loss: 0.02230147086083889\n",
            "Model Saved\n",
            "epoch: 17 step: 209 loss: 0.03114074096083641\n",
            "epoch: 17 step: 219 loss: 0.04446939751505852\n",
            "epoch: 17 step: 229 loss: 0.03845726698637009\n",
            "epoch: 17 step: 239 loss: 0.03069387748837471\n",
            "epoch: 17 step: 249 loss: 0.033154189586639404\n",
            "epoch: 17 step: 259 loss: 0.038020551204681396\n",
            "epoch: 17 step: 269 loss: 0.03894919157028198\n",
            "epoch: 17 step: 279 loss: 0.04087353125214577\n",
            "epoch: 17 step: 289 loss: 0.03285590931773186\n",
            "epoch: 17 step: 299 loss: 0.03756406158208847\n",
            "Model Saved\n",
            "epoch: 17 step: 309 loss: 0.03701154887676239\n",
            "epoch: 17 step: 319 loss: 0.032724060118198395\n",
            "epoch: 17 step: 329 loss: 0.03340546041727066\n",
            "epoch: 17 step: 339 loss: 0.023024260997772217\n",
            "epoch: 17 step: 349 loss: 0.03261951357126236\n",
            "epoch: 17 step: 359 loss: 0.02717948704957962\n",
            "epoch: 17 step: 369 loss: 0.026308227330446243\n",
            "epoch: 17 step: 379 loss: 0.035139888525009155\n",
            "epoch: 17 step: 389 loss: 0.03321479260921478\n",
            "epoch: 17 step: 399 loss: 0.03825452923774719\n",
            "Model Saved\n",
            "epoch: 17 step: 409 loss: 0.04248221218585968\n",
            "epoch: 17 step: 419 loss: 0.031042905524373055\n",
            "epoch: 17 step: 429 loss: 0.029359353706240654\n",
            "epoch: 17 step: 439 loss: 0.028999729081988335\n",
            "epoch: 17 step: 449 loss: 0.026819050312042236\n",
            "epoch: 17 step: 459 loss: 0.03012053668498993\n",
            "epoch: 17 step: 469 loss: 0.029968785122036934\n",
            "epoch: 17 step: 472 loss: 0.021477418020367622\n",
            "epoch: 18 step: 9 loss: 0.030523449182510376\n",
            "epoch: 18 step: 19 loss: 0.029701512306928635\n",
            "epoch: 18 step: 29 loss: 0.03443833813071251\n",
            "epoch: 18 step: 39 loss: 0.03121127560734749\n",
            "epoch: 18 step: 49 loss: 0.023985780775547028\n",
            "epoch: 18 step: 59 loss: 0.03277891129255295\n",
            "epoch: 18 step: 69 loss: 0.04111599922180176\n",
            "epoch: 18 step: 79 loss: 0.03493204712867737\n",
            "epoch: 18 step: 89 loss: 0.030573159456253052\n",
            "epoch: 18 step: 99 loss: 0.02567317895591259\n",
            "Model Saved\n",
            "epoch: 18 step: 109 loss: 0.030988862738013268\n",
            "epoch: 18 step: 119 loss: 0.02841624990105629\n",
            "epoch: 18 step: 129 loss: 0.03836699575185776\n",
            "epoch: 18 step: 139 loss: 0.02676909975707531\n",
            "epoch: 18 step: 149 loss: 0.03894583880901337\n",
            "epoch: 18 step: 159 loss: 0.04150540009140968\n",
            "epoch: 18 step: 169 loss: 0.02724842168390751\n",
            "epoch: 18 step: 179 loss: 0.031764738261699677\n",
            "epoch: 18 step: 189 loss: 0.03291609138250351\n",
            "epoch: 18 step: 199 loss: 0.03897865116596222\n",
            "Model Saved\n",
            "epoch: 18 step: 209 loss: 0.03738484904170036\n",
            "epoch: 18 step: 219 loss: 0.04238773137331009\n",
            "epoch: 18 step: 229 loss: 0.022329986095428467\n",
            "epoch: 18 step: 239 loss: 0.042111679911613464\n",
            "epoch: 18 step: 249 loss: 0.02816605754196644\n",
            "epoch: 18 step: 259 loss: 0.022516151890158653\n",
            "epoch: 18 step: 269 loss: 0.02821033075451851\n",
            "epoch: 18 step: 279 loss: 0.022537440061569214\n",
            "epoch: 18 step: 289 loss: 0.036433350294828415\n",
            "epoch: 18 step: 299 loss: 0.02516571804881096\n",
            "Model Saved\n",
            "epoch: 18 step: 309 loss: 0.02643573470413685\n",
            "epoch: 18 step: 319 loss: 0.04115749150514603\n",
            "epoch: 18 step: 329 loss: 0.03397835046052933\n",
            "epoch: 18 step: 339 loss: 0.02251143753528595\n",
            "epoch: 18 step: 349 loss: 0.028734080493450165\n",
            "epoch: 18 step: 359 loss: 0.04042729362845421\n",
            "epoch: 18 step: 369 loss: 0.02855566143989563\n",
            "epoch: 18 step: 379 loss: 0.03651449829339981\n",
            "epoch: 18 step: 389 loss: 0.03544575721025467\n",
            "epoch: 18 step: 399 loss: 0.03345964476466179\n",
            "Model Saved\n",
            "epoch: 18 step: 409 loss: 0.028637489303946495\n",
            "epoch: 18 step: 419 loss: 0.03457527607679367\n",
            "epoch: 18 step: 429 loss: 0.029414433985948563\n",
            "epoch: 18 step: 439 loss: 0.02985810488462448\n",
            "epoch: 18 step: 449 loss: 0.03367920219898224\n",
            "epoch: 18 step: 459 loss: 0.028328299522399902\n",
            "epoch: 18 step: 469 loss: 0.03380570188164711\n",
            "epoch: 18 step: 472 loss: 0.026664679870009422\n",
            "epoch: 19 step: 9 loss: 0.027191540226340294\n",
            "epoch: 19 step: 19 loss: 0.02894994616508484\n",
            "epoch: 19 step: 29 loss: 0.031050831079483032\n",
            "epoch: 19 step: 39 loss: 0.019502796232700348\n",
            "epoch: 19 step: 49 loss: 0.02586274966597557\n",
            "epoch: 19 step: 59 loss: 0.029546279460191727\n",
            "epoch: 19 step: 69 loss: 0.030389711260795593\n",
            "epoch: 19 step: 79 loss: 0.0343102365732193\n",
            "epoch: 19 step: 89 loss: 0.024428457021713257\n",
            "epoch: 19 step: 99 loss: 0.043491579592227936\n",
            "Model Saved\n",
            "epoch: 19 step: 109 loss: 0.028003351762890816\n",
            "epoch: 19 step: 119 loss: 0.0342424213886261\n",
            "epoch: 19 step: 129 loss: 0.039685264229774475\n",
            "epoch: 19 step: 139 loss: 0.03455130010843277\n",
            "epoch: 19 step: 149 loss: 0.029623400419950485\n",
            "epoch: 19 step: 159 loss: 0.03934633731842041\n",
            "epoch: 19 step: 169 loss: 0.0420062355697155\n",
            "epoch: 19 step: 179 loss: 0.02800000086426735\n",
            "epoch: 19 step: 189 loss: 0.036073293536901474\n",
            "epoch: 19 step: 199 loss: 0.026574701070785522\n",
            "Model Saved\n",
            "epoch: 19 step: 209 loss: 0.03666718304157257\n",
            "epoch: 19 step: 219 loss: 0.023319562897086143\n",
            "epoch: 19 step: 229 loss: 0.032761894166469574\n",
            "epoch: 19 step: 239 loss: 0.032876066863536835\n",
            "epoch: 19 step: 249 loss: 0.03518145531415939\n",
            "epoch: 19 step: 259 loss: 0.039803002029657364\n",
            "epoch: 19 step: 269 loss: 0.024927038699388504\n",
            "epoch: 19 step: 279 loss: 0.03361625224351883\n",
            "epoch: 19 step: 289 loss: 0.02633831277489662\n",
            "epoch: 19 step: 299 loss: 0.04076585918664932\n",
            "Model Saved\n",
            "epoch: 19 step: 309 loss: 0.03620433062314987\n",
            "epoch: 19 step: 319 loss: 0.034668754786252975\n",
            "epoch: 19 step: 329 loss: 0.033992666751146317\n",
            "epoch: 19 step: 339 loss: 0.031789738684892654\n",
            "epoch: 19 step: 349 loss: 0.022369375452399254\n",
            "epoch: 19 step: 359 loss: 0.02739296853542328\n",
            "epoch: 19 step: 369 loss: 0.038593970239162445\n",
            "epoch: 19 step: 379 loss: 0.02111177146434784\n",
            "epoch: 19 step: 389 loss: 0.0324367992579937\n",
            "epoch: 19 step: 399 loss: 0.03381749242544174\n",
            "Model Saved\n",
            "epoch: 19 step: 409 loss: 0.028838958591222763\n",
            "epoch: 19 step: 419 loss: 0.031343974173069\n",
            "epoch: 19 step: 429 loss: 0.034717533737421036\n",
            "epoch: 19 step: 439 loss: 0.02697788178920746\n",
            "epoch: 19 step: 449 loss: 0.028510212898254395\n",
            "epoch: 19 step: 459 loss: 0.025973031297326088\n",
            "epoch: 19 step: 469 loss: 0.027503471821546555\n",
            "epoch: 19 step: 472 loss: 0.025700218975543976\n",
            "epoch: 20 step: 9 loss: 0.03901851922273636\n",
            "epoch: 20 step: 19 loss: 0.03937969356775284\n",
            "epoch: 20 step: 29 loss: 0.023113148286938667\n",
            "epoch: 20 step: 39 loss: 0.026210257783532143\n",
            "epoch: 20 step: 49 loss: 0.022631611675024033\n",
            "epoch: 20 step: 59 loss: 0.02940540388226509\n",
            "epoch: 20 step: 69 loss: 0.02396417036652565\n",
            "epoch: 20 step: 79 loss: 0.033542074263095856\n",
            "epoch: 20 step: 89 loss: 0.025298502296209335\n",
            "epoch: 20 step: 99 loss: 0.027012532576918602\n",
            "Model Saved\n",
            "epoch: 20 step: 109 loss: 0.023059019818902016\n",
            "epoch: 20 step: 119 loss: 0.03294402360916138\n",
            "epoch: 20 step: 129 loss: 0.03955875337123871\n",
            "epoch: 20 step: 139 loss: 0.02846703864634037\n",
            "epoch: 20 step: 149 loss: 0.02118094637989998\n",
            "epoch: 20 step: 159 loss: 0.038022711873054504\n",
            "epoch: 20 step: 169 loss: 0.03268217295408249\n",
            "epoch: 20 step: 179 loss: 0.0340723916888237\n",
            "epoch: 20 step: 189 loss: 0.03032878413796425\n",
            "epoch: 20 step: 199 loss: 0.04144386574625969\n",
            "Model Saved\n",
            "epoch: 20 step: 209 loss: 0.036317065358161926\n",
            "epoch: 20 step: 219 loss: 0.022152680903673172\n",
            "epoch: 20 step: 229 loss: 0.02559499442577362\n",
            "epoch: 20 step: 239 loss: 0.027722502127289772\n",
            "epoch: 20 step: 249 loss: 0.02392762154340744\n",
            "epoch: 20 step: 259 loss: 0.03195187821984291\n",
            "epoch: 20 step: 269 loss: 0.029785865917801857\n",
            "epoch: 20 step: 279 loss: 0.023672685027122498\n",
            "epoch: 20 step: 289 loss: 0.043107450008392334\n",
            "epoch: 20 step: 299 loss: 0.03194575756788254\n",
            "Model Saved\n",
            "epoch: 20 step: 309 loss: 0.040913306176662445\n",
            "epoch: 20 step: 319 loss: 0.029306942597031593\n",
            "epoch: 20 step: 329 loss: 0.030070727691054344\n",
            "epoch: 20 step: 339 loss: 0.025132382288575172\n",
            "epoch: 20 step: 349 loss: 0.03006814792752266\n",
            "epoch: 20 step: 359 loss: 0.031076574698090553\n",
            "epoch: 20 step: 369 loss: 0.03450756520032883\n",
            "epoch: 20 step: 379 loss: 0.032261136919260025\n",
            "epoch: 20 step: 389 loss: 0.025310130789875984\n",
            "epoch: 20 step: 399 loss: 0.02287580445408821\n",
            "Model Saved\n",
            "epoch: 20 step: 409 loss: 0.031395766884088516\n",
            "epoch: 20 step: 419 loss: 0.045243121683597565\n",
            "epoch: 20 step: 429 loss: 0.03688836842775345\n",
            "epoch: 20 step: 439 loss: 0.03975140303373337\n",
            "epoch: 20 step: 449 loss: 0.02377251535654068\n",
            "epoch: 20 step: 459 loss: 0.04760998487472534\n",
            "epoch: 20 step: 469 loss: 0.028847869485616684\n",
            "epoch: 20 step: 472 loss: 0.030001960694789886\n",
            "epoch: 21 step: 9 loss: 0.037379272282123566\n",
            "epoch: 21 step: 19 loss: 0.027139827609062195\n",
            "epoch: 21 step: 29 loss: 0.02871556766331196\n",
            "epoch: 21 step: 39 loss: 0.023809202015399933\n",
            "epoch: 21 step: 49 loss: 0.03481138125061989\n",
            "epoch: 21 step: 59 loss: 0.013025645166635513\n",
            "epoch: 21 step: 69 loss: 0.042109787464141846\n",
            "epoch: 21 step: 79 loss: 0.03323163092136383\n",
            "epoch: 21 step: 89 loss: 0.03861423581838608\n",
            "epoch: 21 step: 99 loss: 0.02639414742588997\n",
            "Model Saved\n",
            "epoch: 21 step: 109 loss: 0.03266939893364906\n",
            "epoch: 21 step: 119 loss: 0.025557924062013626\n",
            "epoch: 21 step: 129 loss: 0.02938428893685341\n",
            "epoch: 21 step: 139 loss: 0.03282921761274338\n",
            "epoch: 21 step: 149 loss: 0.025983372703194618\n",
            "epoch: 21 step: 159 loss: 0.03715356066823006\n",
            "epoch: 21 step: 169 loss: 0.022885523736476898\n",
            "epoch: 21 step: 179 loss: 0.03196871653199196\n",
            "epoch: 21 step: 189 loss: 0.02322806790471077\n",
            "epoch: 21 step: 199 loss: 0.034896109253168106\n",
            "Model Saved\n",
            "epoch: 21 step: 209 loss: 0.02045692503452301\n",
            "epoch: 21 step: 219 loss: 0.028485534712672234\n",
            "epoch: 21 step: 229 loss: 0.027049358934164047\n",
            "epoch: 21 step: 239 loss: 0.027558689936995506\n",
            "epoch: 21 step: 249 loss: 0.025183945894241333\n",
            "epoch: 21 step: 259 loss: 0.03246651217341423\n",
            "epoch: 21 step: 269 loss: 0.029072700068354607\n",
            "epoch: 21 step: 279 loss: 0.028185835108160973\n",
            "epoch: 21 step: 289 loss: 0.04070786386728287\n",
            "epoch: 21 step: 299 loss: 0.03444827347993851\n",
            "Model Saved\n",
            "epoch: 21 step: 309 loss: 0.03325973451137543\n",
            "epoch: 21 step: 319 loss: 0.028798464685678482\n",
            "epoch: 21 step: 329 loss: 0.029962686821818352\n",
            "epoch: 21 step: 339 loss: 0.03406097739934921\n",
            "epoch: 21 step: 349 loss: 0.0336153544485569\n",
            "epoch: 21 step: 359 loss: 0.04104918986558914\n",
            "epoch: 21 step: 369 loss: 0.03276195749640465\n",
            "epoch: 21 step: 379 loss: 0.030732234939932823\n",
            "epoch: 21 step: 389 loss: 0.029289033263921738\n",
            "epoch: 21 step: 399 loss: 0.027748657390475273\n",
            "Model Saved\n",
            "epoch: 21 step: 409 loss: 0.026944339275360107\n",
            "epoch: 21 step: 419 loss: 0.02963516116142273\n",
            "epoch: 21 step: 429 loss: 0.022639095783233643\n",
            "epoch: 21 step: 439 loss: 0.020690707489848137\n",
            "epoch: 21 step: 449 loss: 0.03247595578432083\n",
            "epoch: 21 step: 459 loss: 0.03623826056718826\n",
            "epoch: 21 step: 469 loss: 0.027974287047982216\n",
            "epoch: 21 step: 472 loss: 0.033590205013751984\n",
            "epoch: 22 step: 9 loss: 0.030775580555200577\n",
            "epoch: 22 step: 19 loss: 0.026666440069675446\n",
            "epoch: 22 step: 29 loss: 0.019699284806847572\n",
            "epoch: 22 step: 39 loss: 0.02898333966732025\n",
            "epoch: 22 step: 49 loss: 0.03840557485818863\n",
            "epoch: 22 step: 59 loss: 0.029515568166971207\n",
            "epoch: 22 step: 69 loss: 0.030928583815693855\n",
            "epoch: 22 step: 79 loss: 0.02622179687023163\n",
            "epoch: 22 step: 89 loss: 0.02468916028738022\n",
            "epoch: 22 step: 99 loss: 0.031036268919706345\n",
            "Model Saved\n",
            "epoch: 22 step: 109 loss: 0.027737420052289963\n",
            "epoch: 22 step: 119 loss: 0.03539661318063736\n",
            "epoch: 22 step: 129 loss: 0.027870390564203262\n",
            "epoch: 22 step: 139 loss: 0.03760906308889389\n",
            "epoch: 22 step: 149 loss: 0.02444092184305191\n",
            "epoch: 22 step: 159 loss: 0.02445436641573906\n",
            "epoch: 22 step: 169 loss: 0.028470298275351524\n",
            "epoch: 22 step: 179 loss: 0.033255912363529205\n",
            "epoch: 22 step: 189 loss: 0.02410353347659111\n",
            "epoch: 22 step: 199 loss: 0.025979936122894287\n",
            "Model Saved\n",
            "epoch: 22 step: 209 loss: 0.027302712202072144\n",
            "epoch: 22 step: 219 loss: 0.04404621198773384\n",
            "epoch: 22 step: 229 loss: 0.029797334223985672\n",
            "epoch: 22 step: 239 loss: 0.029626427218317986\n",
            "epoch: 22 step: 249 loss: 0.03842581436038017\n",
            "epoch: 22 step: 259 loss: 0.026328841224312782\n",
            "epoch: 22 step: 269 loss: 0.02599867433309555\n",
            "epoch: 22 step: 279 loss: 0.028364352881908417\n",
            "epoch: 22 step: 289 loss: 0.027053020894527435\n",
            "epoch: 22 step: 299 loss: 0.02037890814244747\n",
            "Model Saved\n",
            "epoch: 22 step: 309 loss: 0.025119846686720848\n",
            "epoch: 22 step: 319 loss: 0.0166221521794796\n",
            "epoch: 22 step: 329 loss: 0.02952718362212181\n",
            "epoch: 22 step: 339 loss: 0.0295719001442194\n",
            "epoch: 22 step: 349 loss: 0.02255355939269066\n",
            "epoch: 22 step: 359 loss: 0.03951413184404373\n",
            "epoch: 22 step: 369 loss: 0.026585273444652557\n",
            "epoch: 22 step: 379 loss: 0.034009478986263275\n",
            "epoch: 22 step: 389 loss: 0.022858142852783203\n",
            "epoch: 22 step: 399 loss: 0.03299812972545624\n",
            "Model Saved\n",
            "epoch: 22 step: 409 loss: 0.029165584594011307\n",
            "epoch: 22 step: 419 loss: 0.032763171941041946\n",
            "epoch: 22 step: 429 loss: 0.03240712732076645\n",
            "epoch: 22 step: 439 loss: 0.03507091477513313\n",
            "epoch: 22 step: 449 loss: 0.028283536434173584\n",
            "epoch: 22 step: 459 loss: 0.01979033090174198\n",
            "epoch: 22 step: 469 loss: 0.033668071031570435\n",
            "epoch: 22 step: 472 loss: 0.026275724172592163\n",
            "epoch: 23 step: 9 loss: 0.02872847393155098\n",
            "epoch: 23 step: 19 loss: 0.04221688583493233\n",
            "epoch: 23 step: 29 loss: 0.034447863698005676\n",
            "epoch: 23 step: 39 loss: 0.02888883464038372\n",
            "epoch: 23 step: 49 loss: 0.02650236338376999\n",
            "epoch: 23 step: 59 loss: 0.021521542221307755\n",
            "epoch: 23 step: 69 loss: 0.02345353551208973\n",
            "epoch: 23 step: 79 loss: 0.030714940279722214\n",
            "epoch: 23 step: 89 loss: 0.019858356565237045\n",
            "epoch: 23 step: 99 loss: 0.025480177253484726\n",
            "Model Saved\n",
            "epoch: 23 step: 109 loss: 0.024903692305088043\n",
            "epoch: 23 step: 119 loss: 0.02434234879910946\n",
            "epoch: 23 step: 129 loss: 0.022472992539405823\n",
            "epoch: 23 step: 139 loss: 0.03953186050057411\n",
            "epoch: 23 step: 149 loss: 0.024953270331025124\n",
            "epoch: 23 step: 159 loss: 0.023921571671962738\n",
            "epoch: 23 step: 169 loss: 0.024171078577637672\n",
            "epoch: 23 step: 179 loss: 0.03292655199766159\n",
            "epoch: 23 step: 189 loss: 0.0331081859767437\n",
            "epoch: 23 step: 199 loss: 0.025874052196741104\n",
            "Model Saved\n",
            "epoch: 23 step: 209 loss: 0.02543041668832302\n",
            "epoch: 23 step: 219 loss: 0.024357561022043228\n",
            "epoch: 23 step: 229 loss: 0.03412104398012161\n",
            "epoch: 23 step: 239 loss: 0.024155136197805405\n",
            "epoch: 23 step: 249 loss: 0.029839035123586655\n",
            "epoch: 23 step: 259 loss: 0.029748637229204178\n",
            "epoch: 23 step: 269 loss: 0.034501705318689346\n",
            "epoch: 23 step: 279 loss: 0.02999594807624817\n",
            "epoch: 23 step: 289 loss: 0.0281223077327013\n",
            "epoch: 23 step: 299 loss: 0.032243240624666214\n",
            "Model Saved\n",
            "epoch: 23 step: 309 loss: 0.02543114684522152\n",
            "epoch: 23 step: 319 loss: 0.020161069929599762\n",
            "epoch: 23 step: 329 loss: 0.020828977227211\n",
            "epoch: 23 step: 339 loss: 0.02204441837966442\n",
            "epoch: 23 step: 349 loss: 0.02825918048620224\n",
            "epoch: 23 step: 359 loss: 0.02577832341194153\n",
            "epoch: 23 step: 369 loss: 0.02585531771183014\n",
            "epoch: 23 step: 379 loss: 0.03217639774084091\n",
            "epoch: 23 step: 389 loss: 0.032798103988170624\n",
            "epoch: 23 step: 399 loss: 0.03143218159675598\n",
            "Model Saved\n",
            "epoch: 23 step: 409 loss: 0.02842007949948311\n",
            "epoch: 23 step: 419 loss: 0.028248485177755356\n",
            "epoch: 23 step: 429 loss: 0.03047589212656021\n",
            "epoch: 23 step: 439 loss: 0.030283721163868904\n",
            "epoch: 23 step: 449 loss: 0.03393389284610748\n",
            "epoch: 23 step: 459 loss: 0.026390742510557175\n",
            "epoch: 23 step: 469 loss: 0.01862391084432602\n",
            "epoch: 23 step: 472 loss: 0.031084435060620308\n",
            "epoch: 24 step: 9 loss: 0.020712852478027344\n",
            "epoch: 24 step: 19 loss: 0.028251148760318756\n",
            "epoch: 24 step: 29 loss: 0.024650603532791138\n",
            "epoch: 24 step: 39 loss: 0.027102269232273102\n",
            "epoch: 24 step: 49 loss: 0.023143911734223366\n",
            "epoch: 24 step: 59 loss: 0.032119546085596085\n",
            "epoch: 24 step: 69 loss: 0.021615760400891304\n",
            "epoch: 24 step: 79 loss: 0.029347965493798256\n",
            "epoch: 24 step: 89 loss: 0.029207812622189522\n",
            "epoch: 24 step: 99 loss: 0.03355429694056511\n",
            "Model Saved\n",
            "epoch: 24 step: 109 loss: 0.03105061501264572\n",
            "epoch: 24 step: 119 loss: 0.026281196624040604\n",
            "epoch: 24 step: 129 loss: 0.03939959406852722\n",
            "epoch: 24 step: 139 loss: 0.025866467505693436\n",
            "epoch: 24 step: 149 loss: 0.027117066085338593\n",
            "epoch: 24 step: 159 loss: 0.030785689130425453\n",
            "epoch: 24 step: 169 loss: 0.03616880625486374\n",
            "epoch: 24 step: 179 loss: 0.023154687136411667\n",
            "epoch: 24 step: 189 loss: 0.020731167867779732\n",
            "epoch: 24 step: 199 loss: 0.028451241552829742\n",
            "Model Saved\n",
            "epoch: 24 step: 209 loss: 0.02633962780237198\n",
            "epoch: 24 step: 219 loss: 0.01777820475399494\n",
            "epoch: 24 step: 229 loss: 0.02792416885495186\n",
            "epoch: 24 step: 239 loss: 0.026594556868076324\n",
            "epoch: 24 step: 249 loss: 0.02487419918179512\n",
            "epoch: 24 step: 259 loss: 0.02543584816157818\n",
            "epoch: 24 step: 269 loss: 0.03255341947078705\n",
            "epoch: 24 step: 279 loss: 0.02347075566649437\n",
            "epoch: 24 step: 289 loss: 0.02164764702320099\n",
            "epoch: 24 step: 299 loss: 0.031628336757421494\n",
            "Model Saved\n",
            "epoch: 24 step: 309 loss: 0.022047284990549088\n",
            "epoch: 24 step: 319 loss: 0.030981766059994698\n",
            "epoch: 24 step: 329 loss: 0.021879661828279495\n",
            "epoch: 24 step: 339 loss: 0.026554454118013382\n",
            "epoch: 24 step: 349 loss: 0.030217863619327545\n",
            "epoch: 24 step: 359 loss: 0.02106098271906376\n",
            "epoch: 24 step: 369 loss: 0.03167156130075455\n",
            "epoch: 24 step: 379 loss: 0.02895437180995941\n",
            "epoch: 24 step: 389 loss: 0.030524753034114838\n",
            "epoch: 24 step: 399 loss: 0.024591729044914246\n",
            "Model Saved\n",
            "epoch: 24 step: 409 loss: 0.028817860409617424\n",
            "epoch: 24 step: 419 loss: 0.02216118574142456\n",
            "epoch: 24 step: 429 loss: 0.02939000353217125\n",
            "epoch: 24 step: 439 loss: 0.02700687013566494\n",
            "epoch: 24 step: 449 loss: 0.02573399245738983\n",
            "epoch: 24 step: 459 loss: 0.024696674197912216\n",
            "epoch: 24 step: 469 loss: 0.02923007495701313\n",
            "epoch: 24 step: 472 loss: 0.025954177603125572\n",
            "epoch: 25 step: 9 loss: 0.029216650873422623\n",
            "epoch: 25 step: 19 loss: 0.0331135094165802\n",
            "epoch: 25 step: 29 loss: 0.024714265018701553\n",
            "epoch: 25 step: 39 loss: 0.020614448934793472\n",
            "epoch: 25 step: 49 loss: 0.025855686515569687\n",
            "epoch: 25 step: 59 loss: 0.020028600469231606\n",
            "epoch: 25 step: 69 loss: 0.03938697651028633\n",
            "epoch: 25 step: 79 loss: 0.029935389757156372\n",
            "epoch: 25 step: 89 loss: 0.02618139237165451\n",
            "epoch: 25 step: 99 loss: 0.02368101291358471\n",
            "Model Saved\n",
            "epoch: 25 step: 109 loss: 0.02862137369811535\n",
            "epoch: 25 step: 119 loss: 0.025355558842420578\n",
            "epoch: 25 step: 129 loss: 0.027866460382938385\n",
            "epoch: 25 step: 139 loss: 0.02075842209160328\n",
            "epoch: 25 step: 149 loss: 0.019700922071933746\n",
            "epoch: 25 step: 159 loss: 0.03270029276609421\n",
            "epoch: 25 step: 169 loss: 0.02408132143318653\n",
            "epoch: 25 step: 179 loss: 0.022451214492321014\n",
            "epoch: 25 step: 189 loss: 0.01750233583152294\n",
            "epoch: 25 step: 199 loss: 0.0235404372215271\n",
            "Model Saved\n",
            "epoch: 25 step: 209 loss: 0.0165829099714756\n",
            "epoch: 25 step: 219 loss: 0.020822489634156227\n",
            "epoch: 25 step: 229 loss: 0.029941583052277565\n",
            "epoch: 25 step: 239 loss: 0.025045650079846382\n",
            "epoch: 25 step: 249 loss: 0.021998174488544464\n",
            "epoch: 25 step: 259 loss: 0.03185947984457016\n",
            "epoch: 25 step: 269 loss: 0.018172811716794968\n",
            "epoch: 25 step: 279 loss: 0.02389458939433098\n",
            "epoch: 25 step: 289 loss: 0.02100229449570179\n",
            "epoch: 25 step: 299 loss: 0.01949198544025421\n",
            "Model Saved\n",
            "epoch: 25 step: 309 loss: 0.02740456908941269\n",
            "epoch: 25 step: 319 loss: 0.019945917651057243\n",
            "epoch: 25 step: 329 loss: 0.025459930300712585\n",
            "epoch: 25 step: 339 loss: 0.02613966539502144\n",
            "epoch: 25 step: 349 loss: 0.019638964906334877\n",
            "epoch: 25 step: 359 loss: 0.029323341324925423\n",
            "epoch: 25 step: 369 loss: 0.0206752996891737\n",
            "epoch: 25 step: 379 loss: 0.022055745124816895\n",
            "epoch: 25 step: 389 loss: 0.030864620581269264\n",
            "epoch: 25 step: 399 loss: 0.033299170434474945\n",
            "Model Saved\n",
            "epoch: 25 step: 409 loss: 0.02768869325518608\n",
            "epoch: 25 step: 419 loss: 0.0285513736307621\n",
            "epoch: 25 step: 429 loss: 0.031028185039758682\n",
            "epoch: 25 step: 439 loss: 0.029206983745098114\n",
            "epoch: 25 step: 449 loss: 0.02757994830608368\n",
            "epoch: 25 step: 459 loss: 0.02779145911335945\n",
            "epoch: 25 step: 469 loss: 0.0253297109156847\n",
            "epoch: 25 step: 472 loss: 0.02166416123509407\n",
            "epoch: 26 step: 9 loss: 0.02363533526659012\n",
            "epoch: 26 step: 19 loss: 0.025221502408385277\n",
            "epoch: 26 step: 29 loss: 0.016853120177984238\n",
            "epoch: 26 step: 39 loss: 0.02443588525056839\n",
            "epoch: 26 step: 49 loss: 0.022393058985471725\n",
            "epoch: 26 step: 59 loss: 0.024980243295431137\n",
            "epoch: 26 step: 69 loss: 0.027961431071162224\n",
            "epoch: 26 step: 79 loss: 0.024027734994888306\n",
            "epoch: 26 step: 89 loss: 0.02533671073615551\n",
            "epoch: 26 step: 99 loss: 0.030435100197792053\n",
            "Model Saved\n",
            "epoch: 26 step: 109 loss: 0.026092402637004852\n",
            "epoch: 26 step: 119 loss: 0.026622770354151726\n",
            "epoch: 26 step: 129 loss: 0.03084876760840416\n",
            "epoch: 26 step: 139 loss: 0.017588865011930466\n",
            "epoch: 26 step: 149 loss: 0.025354575365781784\n",
            "epoch: 26 step: 159 loss: 0.02586752362549305\n",
            "epoch: 26 step: 169 loss: 0.01768525503575802\n",
            "epoch: 26 step: 179 loss: 0.02276502177119255\n",
            "epoch: 26 step: 189 loss: 0.0249939002096653\n",
            "epoch: 26 step: 199 loss: 0.024652091786265373\n",
            "Model Saved\n",
            "epoch: 26 step: 209 loss: 0.02102963998913765\n",
            "epoch: 26 step: 219 loss: 0.026768453419208527\n",
            "epoch: 26 step: 229 loss: 0.035589639097452164\n",
            "epoch: 26 step: 239 loss: 0.03222297132015228\n",
            "epoch: 26 step: 249 loss: 0.04298071563243866\n",
            "epoch: 26 step: 259 loss: 0.022884486243128777\n",
            "epoch: 26 step: 269 loss: 0.02447591722011566\n",
            "epoch: 26 step: 279 loss: 0.02466275915503502\n",
            "epoch: 26 step: 289 loss: 0.020675193518400192\n",
            "epoch: 26 step: 299 loss: 0.01891632191836834\n",
            "Model Saved\n",
            "epoch: 26 step: 309 loss: 0.031098591163754463\n",
            "epoch: 26 step: 319 loss: 0.028845718130469322\n",
            "epoch: 26 step: 329 loss: 0.023234736174345016\n",
            "epoch: 26 step: 339 loss: 0.027294354513287544\n",
            "epoch: 26 step: 349 loss: 0.034368015825748444\n",
            "epoch: 26 step: 359 loss: 0.019425565376877785\n",
            "epoch: 26 step: 369 loss: 0.032451242208480835\n",
            "epoch: 26 step: 379 loss: 0.018314052373170853\n",
            "epoch: 26 step: 389 loss: 0.025831755250692368\n",
            "epoch: 26 step: 399 loss: 0.022239305078983307\n",
            "Model Saved\n",
            "epoch: 26 step: 409 loss: 0.02252461016178131\n",
            "epoch: 26 step: 419 loss: 0.022139495238661766\n",
            "epoch: 26 step: 429 loss: 0.026093740016222\n",
            "epoch: 26 step: 439 loss: 0.022814152762293816\n",
            "epoch: 26 step: 449 loss: 0.018046442419290543\n",
            "epoch: 26 step: 459 loss: 0.01877168007194996\n",
            "epoch: 26 step: 469 loss: 0.01933828368782997\n",
            "epoch: 26 step: 472 loss: 0.024239182472229004\n",
            "epoch: 27 step: 9 loss: 0.02049250900745392\n",
            "epoch: 27 step: 19 loss: 0.022023387253284454\n",
            "epoch: 27 step: 29 loss: 0.019792068749666214\n",
            "epoch: 27 step: 39 loss: 0.027484184131026268\n",
            "epoch: 27 step: 49 loss: 0.02705070748925209\n",
            "epoch: 27 step: 59 loss: 0.02229500375688076\n",
            "epoch: 27 step: 69 loss: 0.021095335483551025\n",
            "epoch: 27 step: 79 loss: 0.02978455275297165\n",
            "epoch: 27 step: 89 loss: 0.020640254020690918\n",
            "epoch: 27 step: 99 loss: 0.026021761819720268\n",
            "Model Saved\n",
            "epoch: 27 step: 109 loss: 0.02128724753856659\n",
            "epoch: 27 step: 119 loss: 0.018311651423573494\n",
            "epoch: 27 step: 129 loss: 0.026659566909074783\n",
            "epoch: 27 step: 139 loss: 0.025792773813009262\n",
            "epoch: 27 step: 149 loss: 0.025754855945706367\n",
            "epoch: 27 step: 159 loss: 0.03367038816213608\n",
            "epoch: 27 step: 169 loss: 0.024998817592859268\n",
            "epoch: 27 step: 179 loss: 0.02083490788936615\n",
            "epoch: 27 step: 189 loss: 0.021993238478899002\n",
            "epoch: 27 step: 199 loss: 0.021284200251102448\n",
            "Model Saved\n",
            "epoch: 27 step: 209 loss: 0.02674635499715805\n",
            "epoch: 27 step: 219 loss: 0.022977560758590698\n",
            "epoch: 27 step: 229 loss: 0.02611592411994934\n",
            "epoch: 27 step: 239 loss: 0.01710101217031479\n",
            "epoch: 27 step: 249 loss: 0.0342884436249733\n",
            "epoch: 27 step: 259 loss: 0.025792617350816727\n",
            "epoch: 27 step: 269 loss: 0.029035259038209915\n",
            "epoch: 27 step: 279 loss: 0.024626415222883224\n",
            "epoch: 27 step: 289 loss: 0.02783798798918724\n",
            "epoch: 27 step: 299 loss: 0.019460666924715042\n",
            "Model Saved\n",
            "epoch: 27 step: 309 loss: 0.021987605839967728\n",
            "epoch: 27 step: 319 loss: 0.028271455317735672\n",
            "epoch: 27 step: 329 loss: 0.020691800862550735\n",
            "epoch: 27 step: 339 loss: 0.02349255234003067\n",
            "epoch: 27 step: 349 loss: 0.03090861067175865\n",
            "epoch: 27 step: 359 loss: 0.023471713066101074\n",
            "epoch: 27 step: 369 loss: 0.02363816648721695\n",
            "epoch: 27 step: 379 loss: 0.026909133419394493\n",
            "epoch: 27 step: 389 loss: 0.029960520565509796\n",
            "epoch: 27 step: 399 loss: 0.02417338639497757\n",
            "Model Saved\n",
            "epoch: 27 step: 409 loss: 0.02761707454919815\n",
            "epoch: 27 step: 419 loss: 0.0270844679325819\n",
            "epoch: 27 step: 429 loss: 0.020161714404821396\n",
            "epoch: 27 step: 439 loss: 0.02231777273118496\n",
            "epoch: 27 step: 449 loss: 0.026253757998347282\n",
            "epoch: 27 step: 459 loss: 0.023746971040964127\n",
            "epoch: 27 step: 469 loss: 0.03166764974594116\n",
            "epoch: 27 step: 472 loss: 0.013410848565399647\n",
            "epoch: 28 step: 9 loss: 0.024323809891939163\n",
            "epoch: 28 step: 19 loss: 0.0230694767087698\n",
            "epoch: 28 step: 29 loss: 0.023540465161204338\n",
            "epoch: 28 step: 39 loss: 0.034592315554618835\n",
            "epoch: 28 step: 49 loss: 0.02233145758509636\n",
            "epoch: 28 step: 59 loss: 0.025489026680588722\n",
            "epoch: 28 step: 69 loss: 0.021408013999462128\n",
            "epoch: 28 step: 79 loss: 0.032053738832473755\n",
            "epoch: 28 step: 89 loss: 0.025799036026000977\n",
            "epoch: 28 step: 99 loss: 0.026271700859069824\n",
            "Model Saved\n",
            "epoch: 28 step: 109 loss: 0.030472740530967712\n",
            "epoch: 28 step: 119 loss: 0.01896597072482109\n",
            "epoch: 28 step: 129 loss: 0.0209144726395607\n",
            "epoch: 28 step: 139 loss: 0.029169248417019844\n",
            "epoch: 28 step: 149 loss: 0.022441208362579346\n",
            "epoch: 28 step: 159 loss: 0.0234241783618927\n",
            "epoch: 28 step: 169 loss: 0.02577195316553116\n",
            "epoch: 28 step: 179 loss: 0.024701345711946487\n",
            "epoch: 28 step: 189 loss: 0.02906319499015808\n",
            "epoch: 28 step: 199 loss: 0.020830858498811722\n",
            "Model Saved\n",
            "epoch: 28 step: 209 loss: 0.025069687515497208\n",
            "epoch: 28 step: 219 loss: 0.01986418291926384\n",
            "epoch: 28 step: 229 loss: 0.028215624392032623\n",
            "epoch: 28 step: 239 loss: 0.02507403865456581\n",
            "epoch: 28 step: 249 loss: 0.021855313330888748\n",
            "epoch: 28 step: 259 loss: 0.02572658285498619\n",
            "epoch: 28 step: 269 loss: 0.030925694853067398\n",
            "epoch: 28 step: 279 loss: 0.021390385925769806\n",
            "epoch: 28 step: 289 loss: 0.027262968942523003\n",
            "epoch: 28 step: 299 loss: 0.019421672448515892\n",
            "Model Saved\n",
            "epoch: 28 step: 309 loss: 0.02322559803724289\n",
            "epoch: 28 step: 319 loss: 0.02261272631585598\n",
            "epoch: 28 step: 329 loss: 0.02495662122964859\n",
            "epoch: 28 step: 339 loss: 0.027641823515295982\n",
            "epoch: 28 step: 349 loss: 0.0264400914311409\n",
            "epoch: 28 step: 359 loss: 0.020689286291599274\n",
            "epoch: 28 step: 369 loss: 0.025026049464941025\n",
            "epoch: 28 step: 379 loss: 0.035188786685466766\n",
            "epoch: 28 step: 389 loss: 0.028909800574183464\n",
            "epoch: 28 step: 399 loss: 0.03043603152036667\n",
            "Model Saved\n",
            "epoch: 28 step: 409 loss: 0.02665259689092636\n",
            "epoch: 28 step: 419 loss: 0.03144507110118866\n",
            "epoch: 28 step: 429 loss: 0.016575824469327927\n",
            "epoch: 28 step: 439 loss: 0.019893862307071686\n",
            "epoch: 28 step: 449 loss: 0.02451189234852791\n",
            "epoch: 28 step: 459 loss: 0.022608881816267967\n",
            "epoch: 28 step: 469 loss: 0.022094614803791046\n",
            "epoch: 28 step: 472 loss: 0.03816176950931549\n",
            "epoch: 29 step: 9 loss: 0.03096785768866539\n",
            "epoch: 29 step: 19 loss: 0.026534046977758408\n",
            "epoch: 29 step: 29 loss: 0.03548216447234154\n",
            "epoch: 29 step: 39 loss: 0.02224608138203621\n",
            "epoch: 29 step: 49 loss: 0.03850201517343521\n",
            "epoch: 29 step: 59 loss: 0.020497655496001244\n",
            "epoch: 29 step: 69 loss: 0.018103480339050293\n",
            "epoch: 29 step: 79 loss: 0.028474681079387665\n",
            "epoch: 29 step: 89 loss: 0.023297788575291634\n",
            "epoch: 29 step: 99 loss: 0.030477840453386307\n",
            "Model Saved\n",
            "epoch: 29 step: 109 loss: 0.033428389579057693\n",
            "epoch: 29 step: 119 loss: 0.01981283724308014\n",
            "epoch: 29 step: 129 loss: 0.019150303676724434\n",
            "epoch: 29 step: 139 loss: 0.02522234618663788\n",
            "epoch: 29 step: 149 loss: 0.022260339930653572\n",
            "epoch: 29 step: 159 loss: 0.026406459510326385\n",
            "epoch: 29 step: 169 loss: 0.019462741911411285\n",
            "epoch: 29 step: 179 loss: 0.02594219706952572\n",
            "epoch: 29 step: 189 loss: 0.02459292858839035\n",
            "epoch: 29 step: 199 loss: 0.021497219800949097\n",
            "Model Saved\n",
            "epoch: 29 step: 209 loss: 0.028384968638420105\n",
            "epoch: 29 step: 219 loss: 0.020034389570355415\n",
            "epoch: 29 step: 229 loss: 0.02194320037961006\n",
            "epoch: 29 step: 239 loss: 0.020474985241889954\n",
            "epoch: 29 step: 249 loss: 0.02791595086455345\n",
            "epoch: 29 step: 259 loss: 0.023099837824702263\n",
            "epoch: 29 step: 269 loss: 0.024868475273251534\n",
            "epoch: 29 step: 279 loss: 0.033823058009147644\n",
            "epoch: 29 step: 289 loss: 0.022819634526968002\n",
            "epoch: 29 step: 299 loss: 0.03883351385593414\n",
            "Model Saved\n",
            "epoch: 29 step: 309 loss: 0.024069666862487793\n",
            "epoch: 29 step: 319 loss: 0.032135311514139175\n",
            "epoch: 29 step: 329 loss: 0.027793582528829575\n",
            "epoch: 29 step: 339 loss: 0.02710093930363655\n",
            "epoch: 29 step: 349 loss: 0.02471795678138733\n",
            "epoch: 29 step: 359 loss: 0.026684796437621117\n",
            "epoch: 29 step: 369 loss: 0.02840072102844715\n",
            "epoch: 29 step: 379 loss: 0.020585929974913597\n",
            "epoch: 29 step: 389 loss: 0.03539325296878815\n",
            "epoch: 29 step: 399 loss: 0.027758026495575905\n",
            "Model Saved\n",
            "epoch: 29 step: 409 loss: 0.025067955255508423\n",
            "epoch: 29 step: 419 loss: 0.01818384788930416\n",
            "epoch: 29 step: 429 loss: 0.03588343411684036\n",
            "epoch: 29 step: 439 loss: 0.024312959983944893\n",
            "epoch: 29 step: 449 loss: 0.01621251180768013\n",
            "epoch: 29 step: 459 loss: 0.02543363720178604\n",
            "epoch: 29 step: 469 loss: 0.02262861281633377\n",
            "epoch: 29 step: 472 loss: 0.03274943307042122\n",
            "Last Model Saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0-Bp8Mi4KjX",
        "colab_type": "code",
        "outputId": "dc9f9991-ddb8-4421-8e34-d21766abbf7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def main():\n",
        "    # GPU Setting\n",
        "    use_cuda = True\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        print('Cuda Available')\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    cnn = CNN()\n",
        "    cnn.to(device)\n",
        "    cnn.eval()\n",
        "    cnn.load_state_dict(torch.load('model.pkl'))\n",
        "    print(\"Model Loaded\")\n",
        "\n",
        "    data_loader = get_test_data_loader()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (images, labels) in enumerate(data_loader):\n",
        "        image = images\n",
        "        variable = Variable(image).to(device)\n",
        "        predict_label = cnn(variable).to(device)\n",
        "\n",
        "        c0 = character_set[np.argmax(predict_label[0, 0:character_set_length].data.numpy())]\n",
        "        c1 = character_set[np.argmax(predict_label[0, character_set_length:2 * character_set_length].data.numpy())]\n",
        "        c2 = character_set[np.argmax(predict_label[0, 2 * character_set_length:3 * character_set_length].data.numpy())]\n",
        "        c3 = character_set[np.argmax(predict_label[0, 3 * character_set_length:4 * character_set_length].data.numpy())]\n",
        "\n",
        "        predict_label = '%s%s%s%s' % (c0, c1, c2, c3)\n",
        "        true_label = decode(labels.numpy()[0])\n",
        "        total += labels.size(0)\n",
        "\n",
        "        if predict_label == true_label:\n",
        "            correct += 1\n",
        "        if total % 200 == 0:\n",
        "            print('Test Accuracy of the model on the %d test images: %f %%' % (total, 100 * correct / total))\n",
        "\n",
        "    print('Test Accuracy of the model on the %d test images: %f %%' % (total, 100 * correct / total))\n",
        "\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Loaded\n",
            "Test Accuracy of the model on the 200 test images: 91.000000 %\n",
            "Test Accuracy of the model on the 400 test images: 88.250000 %\n",
            "Test Accuracy of the model on the 600 test images: 88.166667 %\n",
            "Test Accuracy of the model on the 800 test images: 88.000000 %\n",
            "Test Accuracy of the model on the 1000 test images: 88.800000 %\n",
            "Test Accuracy of the model on the 1200 test images: 88.333333 %\n",
            "Test Accuracy of the model on the 1400 test images: 88.357143 %\n",
            "Test Accuracy of the model on the 1600 test images: 88.062500 %\n",
            "Test Accuracy of the model on the 1800 test images: 87.777778 %\n",
            "Test Accuracy of the model on the 2000 test images: 87.600000 %\n",
            "Test Accuracy of the model on the 2200 test images: 87.636364 %\n",
            "Test Accuracy of the model on the 2400 test images: 87.500000 %\n",
            "Test Accuracy of the model on the 2600 test images: 87.384615 %\n",
            "Test Accuracy of the model on the 2800 test images: 87.535714 %\n",
            "Test Accuracy of the model on the 3000 test images: 87.533333 %\n",
            "Test Accuracy of the model on the 3200 test images: 87.625000 %\n",
            "Test Accuracy of the model on the 3400 test images: 87.794118 %\n",
            "Test Accuracy of the model on the 3600 test images: 87.916667 %\n",
            "Test Accuracy of the model on the 3800 test images: 87.947368 %\n",
            "Test Accuracy of the model on the 4000 test images: 88.150000 %\n",
            "Test Accuracy of the model on the 4200 test images: 87.976190 %\n",
            "Test Accuracy of the model on the 4400 test images: 87.886364 %\n",
            "Test Accuracy of the model on the 4600 test images: 87.847826 %\n",
            "Test Accuracy of the model on the 4800 test images: 87.812500 %\n",
            "Test Accuracy of the model on the 5000 test images: 87.820000 %\n",
            "Test Accuracy of the model on the 5040 test images: 87.817460 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c3Lmmcs7hgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Download\n",
        "from google.colab import files\n",
        "\n",
        "files.download('model.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKdaRgVYRrPm",
        "colab_type": "code",
        "outputId": "d70c1302-9430-4dc1-d02f-0b93a2a822df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "''' Adversarial Captcha Generator '''\n",
        "\n",
        "from __future__ import print_function\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# FGSM attack code\n",
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon * sign_data_grad\n",
        "    # Adding clipping to maintain [0, 1] range\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    # Return the perturbed image\n",
        "    return perturbed_image\n",
        "\n",
        "\n",
        "epsilon = 0.05\n",
        "directory = 'adv'\n",
        "\n",
        "\n",
        "def main():\n",
        "    if os.path.exists(directory):\n",
        "        shutil.rmtree(directory)\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    cnn = CNN()\n",
        "    cnn.to(device)\n",
        "    cnn.eval()\n",
        "    cnn.load_state_dict(torch.load('model.pkl'))\n",
        "    print(\"Model Loaded\")\n",
        "\n",
        "    criterion = nn.MultiLabelSoftMarginLoss()\n",
        "    data_loader = get_test_data_loader()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    count = 1\n",
        "\n",
        "    for i, (images, labels) in enumerate(data_loader):\n",
        "        image = images\n",
        "        variable = Variable(image).to(device)\n",
        "        variable.requires_grad = True\n",
        "        labels = Variable(labels).to(device)\n",
        "        predict_label = cnn(variable)\n",
        "\n",
        "        # plt.imshow(variable.squeeze().detach().cpu().numpy())\n",
        "        # plt.show()\n",
        "\n",
        "        loss = criterion(predict_label, labels.float())\n",
        "        cnn.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        data_grad = variable.grad.data\n",
        "        perturbed_image = fgsm_attack(variable, epsilon, data_grad)\n",
        "        predict_label = cnn(perturbed_image)\n",
        "\n",
        "        # numpy_image = perturbed_image.squeeze().detach().cpu().numpy()\n",
        "        # plt.imshow(numpy_image)\n",
        "        # plt.show()\n",
        "        # fig = plt.gcf()\n",
        "        # fig.savefig(directory + '/' + str(count) + '.png')\n",
        "        count += 1\n",
        "\n",
        "        c0 = character_set[np.argmax(predict_label[0, 0:character_set_length].data.cpu().numpy())]\n",
        "        c1 = character_set[np.argmax(predict_label[0, character_set_length:2 * character_set_length].data.cpu().numpy())]\n",
        "        c2 = character_set[np.argmax(predict_label[0, 2 * character_set_length:3 * character_set_length].data.cpu().numpy())]\n",
        "        c3 = character_set[np.argmax(predict_label[0, 3 * character_set_length:4 * character_set_length].data.cpu().numpy())]\n",
        "\n",
        "        predict_label = '%s%s%s%s' % (c0, c1, c2, c3)\n",
        "        true_label = decode(labels.cpu().numpy()[0])\n",
        "        total += labels.size(0)\n",
        "\n",
        "        if predict_label == true_label:\n",
        "            correct += 1\n",
        "        if total % 20 == 0:\n",
        "            print('Test Accuracy of the model on the %d test images: %f %%' % (total, 100 * correct / total))\n",
        "\n",
        "    print('Test Accuracy of the model on the %d test images: %f %%' % (total, 100 * correct / total))\n",
        "\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Loaded\n",
            "Test Accuracy of the model on the 20 test images: 40.000000 %\n",
            "Test Accuracy of the model on the 40 test images: 45.000000 %\n",
            "Test Accuracy of the model on the 60 test images: 40.000000 %\n",
            "Test Accuracy of the model on the 80 test images: 35.000000 %\n",
            "Test Accuracy of the model on the 100 test images: 32.000000 %\n",
            "Test Accuracy of the model on the 120 test images: 31.666667 %\n",
            "Test Accuracy of the model on the 140 test images: 34.285714 %\n",
            "Test Accuracy of the model on the 160 test images: 34.375000 %\n",
            "Test Accuracy of the model on the 180 test images: 32.777778 %\n",
            "Test Accuracy of the model on the 200 test images: 32.000000 %\n",
            "Test Accuracy of the model on the 220 test images: 33.181818 %\n",
            "Test Accuracy of the model on the 240 test images: 32.916667 %\n",
            "Test Accuracy of the model on the 260 test images: 32.692308 %\n",
            "Test Accuracy of the model on the 280 test images: 31.785714 %\n",
            "Test Accuracy of the model on the 300 test images: 30.666667 %\n",
            "Test Accuracy of the model on the 320 test images: 30.625000 %\n",
            "Test Accuracy of the model on the 340 test images: 30.588235 %\n",
            "Test Accuracy of the model on the 360 test images: 30.000000 %\n",
            "Test Accuracy of the model on the 380 test images: 30.000000 %\n",
            "Test Accuracy of the model on the 400 test images: 29.250000 %\n",
            "Test Accuracy of the model on the 420 test images: 29.047619 %\n",
            "Test Accuracy of the model on the 440 test images: 29.772727 %\n",
            "Test Accuracy of the model on the 460 test images: 29.782609 %\n",
            "Test Accuracy of the model on the 480 test images: 29.791667 %\n",
            "Test Accuracy of the model on the 500 test images: 29.200000 %\n",
            "Test Accuracy of the model on the 520 test images: 29.230769 %\n",
            "Test Accuracy of the model on the 540 test images: 29.259259 %\n",
            "Test Accuracy of the model on the 560 test images: 28.750000 %\n",
            "Test Accuracy of the model on the 580 test images: 29.655172 %\n",
            "Test Accuracy of the model on the 600 test images: 29.833333 %\n",
            "Test Accuracy of the model on the 620 test images: 30.000000 %\n",
            "Test Accuracy of the model on the 640 test images: 30.468750 %\n",
            "Test Accuracy of the model on the 660 test images: 30.151515 %\n",
            "Test Accuracy of the model on the 680 test images: 30.000000 %\n",
            "Test Accuracy of the model on the 700 test images: 30.142857 %\n",
            "Test Accuracy of the model on the 720 test images: 30.277778 %\n",
            "Test Accuracy of the model on the 740 test images: 30.540541 %\n",
            "Test Accuracy of the model on the 760 test images: 30.263158 %\n",
            "Test Accuracy of the model on the 780 test images: 30.512821 %\n",
            "Test Accuracy of the model on the 800 test images: 31.000000 %\n",
            "Test Accuracy of the model on the 820 test images: 30.975610 %\n",
            "Test Accuracy of the model on the 840 test images: 30.833333 %\n",
            "Test Accuracy of the model on the 860 test images: 31.046512 %\n",
            "Test Accuracy of the model on the 880 test images: 31.136364 %\n",
            "Test Accuracy of the model on the 900 test images: 31.000000 %\n",
            "Test Accuracy of the model on the 920 test images: 30.869565 %\n",
            "Test Accuracy of the model on the 940 test images: 30.957447 %\n",
            "Test Accuracy of the model on the 960 test images: 31.145833 %\n",
            "Test Accuracy of the model on the 980 test images: 31.122449 %\n",
            "Test Accuracy of the model on the 1000 test images: 31.400000 %\n",
            "Test Accuracy of the model on the 1020 test images: 31.372549 %\n",
            "Test Accuracy of the model on the 1040 test images: 31.538462 %\n",
            "Test Accuracy of the model on the 1060 test images: 31.886792 %\n",
            "Test Accuracy of the model on the 1080 test images: 32.129630 %\n",
            "Test Accuracy of the model on the 1100 test images: 32.454545 %\n",
            "Test Accuracy of the model on the 1120 test images: 32.410714 %\n",
            "Test Accuracy of the model on the 1140 test images: 32.456140 %\n",
            "Test Accuracy of the model on the 1160 test images: 32.413793 %\n",
            "Test Accuracy of the model on the 1180 test images: 32.457627 %\n",
            "Test Accuracy of the model on the 1200 test images: 32.750000 %\n",
            "Test Accuracy of the model on the 1220 test images: 32.704918 %\n",
            "Test Accuracy of the model on the 1240 test images: 32.822581 %\n",
            "Test Accuracy of the model on the 1260 test images: 32.936508 %\n",
            "Test Accuracy of the model on the 1280 test images: 33.046875 %\n",
            "Test Accuracy of the model on the 1300 test images: 33.384615 %\n",
            "Test Accuracy of the model on the 1320 test images: 33.484848 %\n",
            "Test Accuracy of the model on the 1340 test images: 33.358209 %\n",
            "Test Accuracy of the model on the 1360 test images: 33.529412 %\n",
            "Test Accuracy of the model on the 1380 test images: 33.623188 %\n",
            "Test Accuracy of the model on the 1400 test images: 33.714286 %\n",
            "Test Accuracy of the model on the 1420 test images: 33.732394 %\n",
            "Test Accuracy of the model on the 1440 test images: 33.750000 %\n",
            "Test Accuracy of the model on the 1460 test images: 33.904110 %\n",
            "Test Accuracy of the model on the 1480 test images: 33.783784 %\n",
            "Test Accuracy of the model on the 1500 test images: 33.666667 %\n",
            "Test Accuracy of the model on the 1520 test images: 33.421053 %\n",
            "Test Accuracy of the model on the 1540 test images: 33.311688 %\n",
            "Test Accuracy of the model on the 1560 test images: 33.397436 %\n",
            "Test Accuracy of the model on the 1580 test images: 33.354430 %\n",
            "Test Accuracy of the model on the 1600 test images: 33.125000 %\n",
            "Test Accuracy of the model on the 1620 test images: 33.148148 %\n",
            "Test Accuracy of the model on the 1640 test images: 33.048780 %\n",
            "Test Accuracy of the model on the 1660 test images: 33.072289 %\n",
            "Test Accuracy of the model on the 1680 test images: 33.154762 %\n",
            "Test Accuracy of the model on the 1700 test images: 33.176471 %\n",
            "Test Accuracy of the model on the 1720 test images: 33.372093 %\n",
            "Test Accuracy of the model on the 1740 test images: 33.563218 %\n",
            "Test Accuracy of the model on the 1760 test images: 33.750000 %\n",
            "Test Accuracy of the model on the 1780 test images: 33.539326 %\n",
            "Test Accuracy of the model on the 1800 test images: 33.555556 %\n",
            "Test Accuracy of the model on the 1820 test images: 33.681319 %\n",
            "Test Accuracy of the model on the 1840 test images: 33.641304 %\n",
            "Test Accuracy of the model on the 1860 test images: 33.709677 %\n",
            "Test Accuracy of the model on the 1880 test images: 33.617021 %\n",
            "Test Accuracy of the model on the 1900 test images: 33.684211 %\n",
            "Test Accuracy of the model on the 1920 test images: 33.593750 %\n",
            "Test Accuracy of the model on the 1940 test images: 33.608247 %\n",
            "Test Accuracy of the model on the 1960 test images: 33.724490 %\n",
            "Test Accuracy of the model on the 1980 test images: 33.585859 %\n",
            "Test Accuracy of the model on the 2000 test images: 33.450000 %\n",
            "Test Accuracy of the model on the 2020 test images: 33.415842 %\n",
            "Test Accuracy of the model on the 2040 test images: 33.627451 %\n",
            "Test Accuracy of the model on the 2060 test images: 33.689320 %\n",
            "Test Accuracy of the model on the 2080 test images: 33.605769 %\n",
            "Test Accuracy of the model on the 2100 test images: 33.571429 %\n",
            "Test Accuracy of the model on the 2120 test images: 33.632075 %\n",
            "Test Accuracy of the model on the 2140 test images: 33.691589 %\n",
            "Test Accuracy of the model on the 2160 test images: 33.564815 %\n",
            "Test Accuracy of the model on the 2180 test images: 33.440367 %\n",
            "Test Accuracy of the model on the 2200 test images: 33.409091 %\n",
            "Test Accuracy of the model on the 2220 test images: 33.423423 %\n",
            "Test Accuracy of the model on the 2240 test images: 33.482143 %\n",
            "Test Accuracy of the model on the 2260 test images: 33.362832 %\n",
            "Test Accuracy of the model on the 2280 test images: 33.377193 %\n",
            "Test Accuracy of the model on the 2300 test images: 33.304348 %\n",
            "Test Accuracy of the model on the 2320 test images: 33.448276 %\n",
            "Test Accuracy of the model on the 2340 test images: 33.504274 %\n",
            "Test Accuracy of the model on the 2360 test images: 33.601695 %\n",
            "Test Accuracy of the model on the 2380 test images: 33.613445 %\n",
            "Test Accuracy of the model on the 2400 test images: 33.708333 %\n",
            "Test Accuracy of the model on the 2420 test images: 33.719008 %\n",
            "Test Accuracy of the model on the 2440 test images: 33.606557 %\n",
            "Test Accuracy of the model on the 2460 test images: 33.617886 %\n",
            "Test Accuracy of the model on the 2480 test images: 33.467742 %\n",
            "Test Accuracy of the model on the 2500 test images: 33.400000 %\n",
            "Test Accuracy of the model on the 2520 test images: 33.333333 %\n",
            "Test Accuracy of the model on the 2540 test images: 33.425197 %\n",
            "Test Accuracy of the model on the 2560 test images: 33.359375 %\n",
            "Test Accuracy of the model on the 2580 test images: 33.372093 %\n",
            "Test Accuracy of the model on the 2600 test images: 33.230769 %\n",
            "Test Accuracy of the model on the 2620 test images: 33.358779 %\n",
            "Test Accuracy of the model on the 2640 test images: 33.446970 %\n",
            "Test Accuracy of the model on the 2660 test images: 33.533835 %\n",
            "Test Accuracy of the model on the 2680 test images: 33.395522 %\n",
            "Test Accuracy of the model on the 2700 test images: 33.407407 %\n",
            "Test Accuracy of the model on the 2720 test images: 33.382353 %\n",
            "Test Accuracy of the model on the 2740 test images: 33.357664 %\n",
            "Test Accuracy of the model on the 2760 test images: 33.297101 %\n",
            "Test Accuracy of the model on the 2780 test images: 33.201439 %\n",
            "Test Accuracy of the model on the 2800 test images: 33.178571 %\n",
            "Test Accuracy of the model on the 2820 test images: 33.120567 %\n",
            "Test Accuracy of the model on the 2840 test images: 32.992958 %\n",
            "Test Accuracy of the model on the 2860 test images: 33.111888 %\n",
            "Test Accuracy of the model on the 2880 test images: 33.159722 %\n",
            "Test Accuracy of the model on the 2900 test images: 33.137931 %\n",
            "Test Accuracy of the model on the 2920 test images: 33.116438 %\n",
            "Test Accuracy of the model on the 2940 test images: 33.163265 %\n",
            "Test Accuracy of the model on the 2960 test images: 33.141892 %\n",
            "Test Accuracy of the model on the 2980 test images: 33.087248 %\n",
            "Test Accuracy of the model on the 3000 test images: 33.133333 %\n",
            "Test Accuracy of the model on the 3020 test images: 33.311258 %\n",
            "Test Accuracy of the model on the 3040 test images: 33.289474 %\n",
            "Test Accuracy of the model on the 3060 test images: 33.366013 %\n",
            "Test Accuracy of the model on the 3080 test images: 33.311688 %\n",
            "Test Accuracy of the model on the 3100 test images: 33.225806 %\n",
            "Test Accuracy of the model on the 3120 test images: 33.333333 %\n",
            "Test Accuracy of the model on the 3140 test images: 33.280255 %\n",
            "Test Accuracy of the model on the 3160 test images: 33.227848 %\n",
            "Test Accuracy of the model on the 3180 test images: 33.176101 %\n",
            "Test Accuracy of the model on the 3200 test images: 33.156250 %\n",
            "Test Accuracy of the model on the 3220 test images: 33.229814 %\n",
            "Test Accuracy of the model on the 3240 test images: 33.271605 %\n",
            "Test Accuracy of the model on the 3260 test images: 33.343558 %\n",
            "Test Accuracy of the model on the 3280 test images: 33.353659 %\n",
            "Test Accuracy of the model on the 3300 test images: 33.272727 %\n",
            "Test Accuracy of the model on the 3320 test images: 33.283133 %\n",
            "Test Accuracy of the model on the 3340 test images: 33.233533 %\n",
            "Test Accuracy of the model on the 3360 test images: 33.244048 %\n",
            "Test Accuracy of the model on the 3380 test images: 33.254438 %\n",
            "Test Accuracy of the model on the 3400 test images: 33.294118 %\n",
            "Test Accuracy of the model on the 3420 test images: 33.216374 %\n",
            "Test Accuracy of the model on the 3440 test images: 33.226744 %\n",
            "Test Accuracy of the model on the 3460 test images: 33.294798 %\n",
            "Test Accuracy of the model on the 3480 test images: 33.333333 %\n",
            "Test Accuracy of the model on the 3500 test images: 33.314286 %\n",
            "Test Accuracy of the model on the 3520 test images: 33.323864 %\n",
            "Test Accuracy of the model on the 3540 test images: 33.305085 %\n",
            "Test Accuracy of the model on the 3560 test images: 33.398876 %\n",
            "Test Accuracy of the model on the 3580 test images: 33.379888 %\n",
            "Test Accuracy of the model on the 3600 test images: 33.305556 %\n",
            "Test Accuracy of the model on the 3620 test images: 33.370166 %\n",
            "Test Accuracy of the model on the 3640 test images: 33.296703 %\n",
            "Test Accuracy of the model on the 3660 test images: 33.196721 %\n",
            "Test Accuracy of the model on the 3680 test images: 33.233696 %\n",
            "Test Accuracy of the model on the 3700 test images: 33.162162 %\n",
            "Test Accuracy of the model on the 3720 test images: 33.225806 %\n",
            "Test Accuracy of the model on the 3740 test images: 33.208556 %\n",
            "Test Accuracy of the model on the 3760 test images: 33.244681 %\n",
            "Test Accuracy of the model on the 3780 test images: 33.227513 %\n",
            "Test Accuracy of the model on the 3800 test images: 33.184211 %\n",
            "Test Accuracy of the model on the 3820 test images: 33.167539 %\n",
            "Test Accuracy of the model on the 3840 test images: 33.098958 %\n",
            "Test Accuracy of the model on the 3860 test images: 33.160622 %\n",
            "Test Accuracy of the model on the 3880 test images: 33.041237 %\n",
            "Test Accuracy of the model on the 3900 test images: 33.000000 %\n",
            "Test Accuracy of the model on the 3920 test images: 33.010204 %\n",
            "Test Accuracy of the model on the 3940 test images: 32.918782 %\n",
            "Test Accuracy of the model on the 3960 test images: 32.828283 %\n",
            "Test Accuracy of the model on the 3980 test images: 32.788945 %\n",
            "Test Accuracy of the model on the 4000 test images: 32.700000 %\n",
            "Test Accuracy of the model on the 4020 test images: 32.761194 %\n",
            "Test Accuracy of the model on the 4040 test images: 32.747525 %\n",
            "Test Accuracy of the model on the 4060 test images: 32.807882 %\n",
            "Test Accuracy of the model on the 4080 test images: 32.892157 %\n",
            "Test Accuracy of the model on the 4100 test images: 32.780488 %\n",
            "Test Accuracy of the model on the 4120 test images: 32.815534 %\n",
            "Test Accuracy of the model on the 4140 test images: 32.826087 %\n",
            "Test Accuracy of the model on the 4160 test images: 32.764423 %\n",
            "Test Accuracy of the model on the 4180 test images: 32.822967 %\n",
            "Test Accuracy of the model on the 4200 test images: 32.880952 %\n",
            "Test Accuracy of the model on the 4220 test images: 32.938389 %\n",
            "Test Accuracy of the model on the 4240 test images: 32.877358 %\n",
            "Test Accuracy of the model on the 4260 test images: 32.887324 %\n",
            "Test Accuracy of the model on the 4280 test images: 32.873832 %\n",
            "Test Accuracy of the model on the 4300 test images: 32.906977 %\n",
            "Test Accuracy of the model on the 4320 test images: 32.893519 %\n",
            "Test Accuracy of the model on the 4340 test images: 32.880184 %\n",
            "Test Accuracy of the model on the 4360 test images: 32.866972 %\n",
            "Test Accuracy of the model on the 4380 test images: 32.831050 %\n",
            "Test Accuracy of the model on the 4400 test images: 32.840909 %\n",
            "Test Accuracy of the model on the 4420 test images: 32.805430 %\n",
            "Test Accuracy of the model on the 4440 test images: 32.837838 %\n",
            "Test Accuracy of the model on the 4460 test images: 32.847534 %\n",
            "Test Accuracy of the model on the 4480 test images: 32.767857 %\n",
            "Test Accuracy of the model on the 4500 test images: 32.866667 %\n",
            "Test Accuracy of the model on the 4520 test images: 32.831858 %\n",
            "Test Accuracy of the model on the 4540 test images: 32.819383 %\n",
            "Test Accuracy of the model on the 4560 test images: 32.872807 %\n",
            "Test Accuracy of the model on the 4580 test images: 32.838428 %\n",
            "Test Accuracy of the model on the 4600 test images: 32.782609 %\n",
            "Test Accuracy of the model on the 4620 test images: 32.792208 %\n",
            "Test Accuracy of the model on the 4640 test images: 32.801724 %\n",
            "Test Accuracy of the model on the 4660 test images: 32.789700 %\n",
            "Test Accuracy of the model on the 4680 test images: 32.777778 %\n",
            "Test Accuracy of the model on the 4700 test images: 32.787234 %\n",
            "Test Accuracy of the model on the 4720 test images: 32.775424 %\n",
            "Test Accuracy of the model on the 4740 test images: 32.763713 %\n",
            "Test Accuracy of the model on the 4760 test images: 32.710084 %\n",
            "Test Accuracy of the model on the 4780 test images: 32.698745 %\n",
            "Test Accuracy of the model on the 4800 test images: 32.666667 %\n",
            "Test Accuracy of the model on the 4820 test images: 32.655602 %\n",
            "Test Accuracy of the model on the 4840 test images: 32.665289 %\n",
            "Test Accuracy of the model on the 4860 test images: 32.633745 %\n",
            "Test Accuracy of the model on the 4880 test images: 32.602459 %\n",
            "Test Accuracy of the model on the 4900 test images: 32.571429 %\n",
            "Test Accuracy of the model on the 4920 test images: 32.560976 %\n",
            "Test Accuracy of the model on the 4940 test images: 32.530364 %\n",
            "Test Accuracy of the model on the 4960 test images: 32.500000 %\n",
            "Test Accuracy of the model on the 4980 test images: 32.510040 %\n",
            "Test Accuracy of the model on the 5000 test images: 32.540000 %\n",
            "Test Accuracy of the model on the 5020 test images: 32.490040 %\n",
            "Test Accuracy of the model on the 5040 test images: 32.440476 %\n",
            "Test Accuracy of the model on the 5040 test images: 32.440476 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}